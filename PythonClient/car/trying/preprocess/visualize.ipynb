{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e021412d",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcluster\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m KMeans\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m  \u001b[39m\u001b[34;01mopen3d\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mo3d\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'sklearn'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "import  open3d as o3d\n",
    "import numpy as np\n",
    "import open3d as o3d\n",
    "import os\n",
    "import re\n",
    "file_num = 0\n",
    "\n",
    "# Example data (replace with actual point cloud and initial labels)\n",
    "# load points and labels\n",
    "label_to_color = {\n",
    "        0: (0.0, 0.0, 0.0),\n",
    "        1: (0.0, 1.0, 0.0),\n",
    "        2: (1.0, 0.0, 0.0),\n",
    "    }\n",
    "for file_num in range(8):\n",
    "    names = os.listdir(f'../data/{file_num}')\n",
    "    pattern_ply = re.compile(r'^[^\\.]+\\.ply$')\n",
    "    names_ply = [n for n in names if pattern_ply.match(n)]\n",
    "    for i in range(1, len(names_ply) + 1):\n",
    "        pc_path = f'../data/{file_num}/{i}.ply'  # replace with your point cloud file\n",
    "        label_path = f'../data/{file_num}/{i}_labels.npy'  # replace with your label file\n",
    "        pcd = o3d.io.read_point_cloud(pc_path)\n",
    "        points = np.asarray(pcd.points)        # shape (N, 3)\n",
    "        labels = np.load(label_path).reshape(-1).astype(np.int32)# 1 = safe, 0 = unsafe, -1 = unlabeled\n",
    "\n",
    "        # Apply K-Means clustering to all points\n",
    "        K = 25 # for example, 15 clusters (tune this as needed)\n",
    "        kmeans = KMeans(n_clusters=K, random_state=42)\n",
    "        cluster_ids = kmeans.fit_predict(points)\n",
    "\n",
    "        # Determine majority label in each cluster\n",
    "        cluster_label = {}  # map cluster_id -> assigned label\n",
    "        for cid in range(K):\n",
    "            idx = np.where(cluster_ids == cid)[0]               # indices of points in this cluster\n",
    "            labeled_idx = idx[labels[idx] != -1]                # indices of labeled points in cluster\n",
    "            if labeled_idx.size == 0:\n",
    "                continue  # no label info in this cluster; skip assigning\n",
    "            # Count safe vs unsafe among known labels in cluster\n",
    "            safe_count = np.sum(labels[labeled_idx] == 1)\n",
    "            unsafe_count = np.sum(labels[labeled_idx] == 2)\n",
    "            # Decide label if one class dominates\n",
    "            total_labeled = safe_count + unsafe_count\n",
    "            if total_labeled > 0:\n",
    "                majority_label = 1 if safe_count > unsafe_count else 2\n",
    "                frac = max(safe_count, unsafe_count) / total_labeled\n",
    "                # print(f\"Cluster {cid} - Safe: {safe_count}, Unsafe: {unsafe_count}, Fraction: {frac:.2f}\")\n",
    "                if frac >= 0.70:  # e.g., require at least 70% agreement\n",
    "                    cluster_label[cid] = majority_label\n",
    "        # Assign labels to unlabeled points based on cluster majority\n",
    "        new_labels = labels.copy()\n",
    "        for cid, lbl in cluster_label.items():\n",
    "            # print(f\"Cluster {cid} majority label: {lbl}\")\n",
    "            # print(f\"Cluster {cid} majority label: {lbl}\")\n",
    "            idx = np.where(cluster_ids == cid)[0]\n",
    "            # Label only those that were unlabeled\n",
    "            unl_idx = idx[new_labels[idx] == 0]\n",
    "        #     new_labels[unl_idx] = lbl\n",
    "        # # save the new labels\n",
    "        # print(\"Total number oif pints\", len(new_labels)-len(labels))\n",
    "        # print(f\"number of zero label before the point cloud: {np.sum(new_labels == 0)- np.sum(labels == 0)}\")\n",
    "        np.save(f'../data/{file_num}/{i}_labels.npy', new_labels)\n",
    "        print(\"done \", file_num)\n",
    "    # print(f\"number of zero label after the point cloud: {np.sum(new_labels == 0)}\")\n",
    "    # # 'new_labels' now contains expanded labels for points that met the criteria\n",
    "    # print(\"unique labels after clustering:\", np.unique(new_labels))\n",
    "    # # visualize the results\n",
    "    # pcd.colors = o3d.utility.Vector3dVector(np.array([label_to_color[l] for l in new_labels], dtype=np.float64))\n",
    "    # o3d.visualization.draw_geometries([pcd])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d44c2dc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import open3d as o3d\n",
    "import os\n",
    "import re\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from collections import Counter\n",
    "\n",
    "label_to_color = {\n",
    "    0: (0.0, 0.0, 0.0),\n",
    "    1: (0.0, 1.0, 0.0),\n",
    "    2: (1.0, 0.0, 0.0),\n",
    "}\n",
    "\n",
    "k = 50  # Number of neighbors\n",
    "threshold = 0.4  # 70% majority required to assign label\n",
    "\n",
    "for file_num in range(8):\n",
    "    names = os.listdir(f'../data/{file_num}')\n",
    "    pattern_ply = re.compile(r'^[^\\.]+\\.ply$')\n",
    "    names_ply = [n for n in names if pattern_ply.match(n)]\n",
    "    \n",
    "    for i in range(1, len(names_ply) + 1):\n",
    "        pc_path = f'../data/{file_num}/{i}.ply'\n",
    "        label_path = f'../data/{file_num}/{i}_labels.npy'\n",
    "        \n",
    "        pcd = o3d.io.read_point_cloud(pc_path)\n",
    "        points = np.asarray(pcd.points)\n",
    "        labels = np.load(label_path).reshape(-1).astype(np.int32)\n",
    "\n",
    "        labeled_idx = np.where((labels == 1) | (labels == 2))[0]\n",
    "        unlabeled_idx = np.where(labels == 0)[0]\n",
    "\n",
    "        if labeled_idx.size == 0 or unlabeled_idx.size == 0:\n",
    "            continue\n",
    "\n",
    "        labeled_points = points[labeled_idx]\n",
    "        unlabeled_points = points[unlabeled_idx]\n",
    "        labeled_labels = labels[labeled_idx]\n",
    "\n",
    "        nbrs = NearestNeighbors(n_neighbors=k, algorithm='auto').fit(labeled_points)\n",
    "        distances, indices = nbrs.kneighbors(unlabeled_points)\n",
    "\n",
    "        new_labels = labels.copy()\n",
    "\n",
    "        for j, neighbor_idxs in enumerate(indices):\n",
    "            neighbor_labels = labeled_labels[neighbor_idxs]\n",
    "            label_counts = Counter(neighbor_labels)\n",
    "            most_common_label, count = label_counts.most_common(1)[0]\n",
    "            if count / k >= threshold:\n",
    "                new_labels[unlabeled_idx[j]] = most_common_label\n",
    "\n",
    "        # np.save(f'../data/{file_num}/{i}_labels.npy', new_labels)\n",
    "        # print(\"Done:\", file_num, i)\n",
    "        # Map labels to colors (make sure the label_to_color dictionary is defined)\n",
    "        colors = np.array([label_to_color.get(lbl, (0.5, 0.5, 0.5)) for lbl in new_labels], dtype=np.float64)\n",
    "        pcd.colors = o3d.utility.Vector3dVector(colors)\n",
    "        o3d.visualization.draw_geometries([pcd], window_name=f\"Point Cloud {file_num}-{i}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b067ec7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-d6eeb72d1c4e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m         \u001b[1;31m# 5) Visualize\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 42\u001b[1;33m         \u001b[0mo3d\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvisualization\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdraw_geometries\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mground_pc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobstacle_pc\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import open3d as o3d\n",
    "import CSF\n",
    "import os, re\n",
    "# ---- your existing setup ----\n",
    "# file_num = 0\n",
    "# i = 5\n",
    "for file_num in range(8):\n",
    "    file_num =7\n",
    "    names = os.listdir(f'../data/{file_num}')\n",
    "    pattern_ply = re.compile(r'^[^\\.]+\\.ply$')\n",
    "    names_ply = [n for n in names if pattern_ply.match(n)]\n",
    "    for i in range(1, len(names_ply) + 1):\n",
    "        pcd = o3d.io.read_point_cloud(f'../data/{file_num}/{i}.ply')\n",
    "        xyz = np.asarray(pcd.points)\n",
    "\n",
    "        # 2) Configure the CSF filter\n",
    "        csf = CSF.CSF()\n",
    "        csf.params.bSloopSmooth    = False    # smooth out small terrain noise\n",
    "        csf.params.cloth_resolution = 0.03    # size of cloth mesh cells (m)\n",
    "        # (optional) tweak these too:\n",
    "        csf.params.rigidness    = 1\n",
    "        csf.params.iterations   = 500\n",
    "        csf.params.class_threshold = 0.1\n",
    "\n",
    "        # 3) Run the filter\n",
    "        csf.setPointCloud(xyz)\n",
    "        ground_idx     = CSF.VecInt()       # will hold indices of ground points\n",
    "        non_ground_idx = CSF.VecInt()       # will hold indices of obstacles\n",
    "        csf.do_filtering(ground_idx, non_ground_idx)\n",
    "\n",
    "        # 4) Extract and color\n",
    "        ground_pts   = xyz[np.array(list(ground_idx),     dtype=int)]\n",
    "        obstacle_pts = xyz[np.array(list(non_ground_idx), dtype=int)]\n",
    "        ground_pc     = o3d.geometry.PointCloud(o3d.utility.Vector3dVector(ground_pts))\n",
    "        obstacle_pc   = o3d.geometry.PointCloud(o3d.utility.Vector3dVector(obstacle_pts))\n",
    "\n",
    "        ground_pc.paint_uniform_color([0.0, 1.0, 0.0])   # gray = ground\n",
    "        obstacle_pc.paint_uniform_color([1.0, 0.0, 0.0]) # red  = obstacles\n",
    "\n",
    "        # 5) Visualize\n",
    "        o3d.visualization.draw_geometries([ground_pc, obstacle_pc])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5188a7c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-94f693d6496b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     69\u001b[0m             \u001b[0mwidth\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m800\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     70\u001b[0m             \u001b[0mheight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m600\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 71\u001b[1;33m             \u001b[0mmesh_show_back_face\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     72\u001b[0m         )\n\u001b[0;32m     73\u001b[0m         \u001b[1;31m# visua;oze\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import open3d as o3d\n",
    "import CSF\n",
    "\n",
    "BASE_DIR = '../data'\n",
    "SLOPE_THRESHOLD_DEG = 10.0   # ramp if normal deviates more than this from vertical\n",
    "\n",
    "for file_num in range(8):\n",
    "    file_num =7\n",
    "    folder = os.path.join(BASE_DIR, str(file_num))\n",
    "    if not os.path.isdir(folder):\n",
    "        continue\n",
    "\n",
    "    ply_files = sorted(f for f in os.listdir(folder) if f.lower().endswith('.ply'))\n",
    "    for ply_name in ply_files:\n",
    "        # 1) load\n",
    "        ply_path = os.path.join(folder, ply_name)\n",
    "        pcd = o3d.io.read_point_cloud(ply_path)\n",
    "        xyz = np.asarray(pcd.points)\n",
    "\n",
    "        # 2) estimate normals once on full cloud\n",
    "        pcd.estimate_normals(search_param=o3d.geometry.KDTreeSearchParamKNN(knn=30))\n",
    "        normals = np.asarray(pcd.normals)  # shape (N,3)\n",
    "\n",
    "        # 3) run CSF\n",
    "        csf = CSF.CSF()\n",
    "        csf.params.bSloopSmooth     = True\n",
    "        csf.params.cloth_resolution = 0.1\n",
    "        csf.params.rigidness        = 5\n",
    "        csf.params.iterations       = 500\n",
    "        csf.params.class_threshold  = 0.5\n",
    "\n",
    "        csf.setPointCloud(xyz)\n",
    "        ground_idx     = CSF.VecInt()\n",
    "        non_ground_idx = CSF.VecInt()\n",
    "        csf.do_filtering(ground_idx, non_ground_idx)\n",
    "\n",
    "        # convert to Python lists\n",
    "        ground_idx_list     = np.array(list(ground_idx), dtype=int)\n",
    "        non_ground_idx_list = np.array(list(non_ground_idx), dtype=int)\n",
    "\n",
    "        # 4) detect ramps in the ground set\n",
    "        g_normals = normals[ground_idx_list]                   # normals for CSF‐ground\n",
    "        # angle from vertical = arccos(|n·[0,0,1]|)\n",
    "        angles = np.degrees(np.arccos(np.clip(np.abs(g_normals[:,2]), -1.0, 1.0)))\n",
    "        ramp_mask = angles > SLOPE_THRESHOLD_DEG\n",
    "\n",
    "        ramp_idx_global = ground_idx_list[ramp_mask]           # these are the ramps\n",
    "        flat_idx_global = ground_idx_list[~ramp_mask]          # truly flat ground\n",
    "\n",
    "        # 5) assemble final indices\n",
    "        final_ground_idx   = flat_idx_global\n",
    "        final_obstacle_idx = np.concatenate([non_ground_idx_list, ramp_idx_global])\n",
    "\n",
    "        # 6) extract point clouds\n",
    "        ground_pc   = o3d.geometry.PointCloud(o3d.utility.Vector3dVector(xyz[final_ground_idx]))\n",
    "        obstacle_pc = o3d.geometry.PointCloud(o3d.utility.Vector3dVector(xyz[final_obstacle_idx]))\n",
    "\n",
    "        # color: green=flat ground, blue=ramps, red=other obstacles\n",
    "        ground_pc.paint_uniform_color([0.0, 1.0, 0.0])\n",
    "        # optionally visualize ramps separately:\n",
    "        ramp_pc = o3d.geometry.PointCloud(o3d.utility.Vector3dVector(xyz[ramp_idx_global]))\n",
    "        ramp_pc.paint_uniform_color([0.0, 0.0, 1.0])\n",
    "        obstacle_pc.paint_uniform_color([1.0, 0.0, 0.0])\n",
    "        o3d.visualization.draw_geometries(\n",
    "            [ground_pc, ramp_pc, obstacle_pc],\n",
    "            window_name=f\"Segmentation: {ply_name}\",\n",
    "            width=800,\n",
    "            height=600,\n",
    "            mesh_show_back_face=True\n",
    "        )\n",
    "        # visua;oze \n",
    "        # # 7) write or visualize\n",
    "        # o3d.io.write_point_cloud(os.path.join(folder, ply_name.replace('.ply','_flat.ply')),   ground_pc)\n",
    "        # o3d.io.write_point_cloud(os.path.join(folder, ply_name.replace('.ply','_ramp.ply')),   ramp_pc)\n",
    "        # o3d.io.write_point_cloud(os.path.join(folder, ply_name.replace('.ply','_obst.ply')),   obstacle_pc)\n",
    "\n",
    "        # print(f\"{ply_name}: {len(flat_idx_global)} flat, {len(ramp_idx_global)} ramp, \"\n",
    "        #       f\"{len(non_ground_idx_list)} other obstacles\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eb3c746",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import open3d as o3d\n",
    "import CSF\n",
    "import os, re\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from collections import Counter\n",
    "\n",
    "for file_num in range(8):\n",
    "    file_num =  0 # <- You overwrite this, so the loop always uses 7\n",
    "    names = os.listdir(f'../data/{file_num}')\n",
    "    pattern_ply = re.compile(r'^[^\\.]+\\.ply$')\n",
    "    names_ply = [n for n in names if pattern_ply.match(n)]\n",
    "\n",
    "    for i in range(1, len(names_ply) + 1):\n",
    "        # Load point cloud\n",
    "        pcd = o3d.io.read_point_cloud(f'../data/{file_num}/{i}.ply')\n",
    "        xyz = np.asarray(pcd.points)\n",
    "        \n",
    "        # Load labels\n",
    "        label_path = f'../data/{file_num}/{i}_labels.npy'\n",
    "        labels = np.load(label_path).reshape(-1).astype(np.int32)\n",
    "\n",
    "        # --- Run CSF to classify ground vs obstacle ---\n",
    "        csf = CSF.CSF()\n",
    "        csf.params.bSloopSmooth = False\n",
    "        csf.params.cloth_resolution = 0.03\n",
    "        csf.params.rigidness = 1\n",
    "        csf.params.iterations = 500\n",
    "        csf.params.class_threshold = 0.1\n",
    "\n",
    "        csf.setPointCloud(xyz)\n",
    "        ground_idx = CSF.VecInt()\n",
    "        non_ground_idx = CSF.VecInt()\n",
    "        csf.do_filtering(ground_idx, non_ground_idx)\n",
    "\n",
    "        # Convert CSF indices to numpy arrays\n",
    "        ground_idx = np.array(list(ground_idx), dtype=int)\n",
    "        obstacle_idx = np.array(list(non_ground_idx), dtype=int)\n",
    "\n",
    "        # Assign ground/obstacle labels (1 = safe, 2 = unsafe)\n",
    "        csf_labels = np.zeros_like(labels)\n",
    "        csf_labels[ground_idx] = 1\n",
    "        csf_labels[obstacle_idx] = 2\n",
    "\n",
    "        # --- Apply KNN to propagate CSF labels to originally unlabeled points ---\n",
    "        k = 10\n",
    "        threshold = 0.7\n",
    "\n",
    "        labeled_idx = np.where(csf_labels != 0)[0]\n",
    "        unlabeled_idx = np.where(labels == 0)[0]\n",
    "\n",
    "        if labeled_idx.size > 0 and unlabeled_idx.size > 0:\n",
    "            knn = NearestNeighbors(n_neighbors=k).fit(xyz[labeled_idx])\n",
    "            distances, neighbor_indices = knn.kneighbors(xyz[unlabeled_idx])\n",
    "\n",
    "            for j, neighbors in enumerate(neighbor_indices):\n",
    "                neighbor_labels = csf_labels[labeled_idx[neighbors]]\n",
    "                most_common, count = Counter(neighbor_labels).most_common(1)[0]\n",
    "                if count / k >= threshold:\n",
    "                    labels[unlabeled_idx[j]] = most_common\n",
    "\n",
    "        # Save updated labels\n",
    "        np.save(label_path, labels)\n",
    "\n",
    "        # --- Visualization ---\n",
    "        label_to_color = {\n",
    "            0: (0.5, 0.5, 0.5),  # unlabeled\n",
    "            1: (0.0, 1.0, 0.0),  # safe\n",
    "            2: (1.0, 0.0, 0.0),  # unsafe\n",
    "        }\n",
    "\n",
    "        colors = np.array([label_to_color.get(l, (0.5, 0.5, 0.5)) for l in labels])\n",
    "        pcd.colors = o3d.utility.Vector3dVector(colors)\n",
    "        o3d.visualization.draw_geometries([pcd], window_name=f\"File {file_num}, Frame {i}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3c23dfe",
   "metadata": {},
   "source": [
    "clothes labelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "957716da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:36<00:00, 36.07s/it]\n"
     ]
    }
   ],
   "source": [
    "import open3d as o3d\n",
    "import numpy as np\n",
    "import os, re, cv2\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from collections import Counter\n",
    "import CSF\n",
    "from tqdm import tqdm\n",
    "output_frame_dir = \"rendered_frames\"\n",
    "os.makedirs(output_frame_dir, exist_ok=True)\n",
    "\n",
    "\n",
    "\n",
    "for file_num in tqdm(range(1,2)):  # Just 0 for now\n",
    "    file_output_dir = os.path.join(output_frame_dir, str(file_num))\n",
    "    os.makedirs(file_output_dir, exist_ok=True)\n",
    "    names = os.listdir(f'../data/{file_num}')\n",
    "    pattern_ply = re.compile(r'^[^\\.]+\\.ply$')\n",
    "    names_ply = sorted([n for n in names if pattern_ply.match(n)], key=lambda x: int(x.split('.')[0]))\n",
    "    frame_id = 0\n",
    "    for i in range(1, len(names_ply) + 1):\n",
    "        # Load point cloud\n",
    "        pcd = o3d.io.read_point_cloud(f'../data/{file_num}/{i}.ply')\n",
    "        xyz = np.asarray(pcd.points)\n",
    "\n",
    "        label_path = f'../data/{file_num}/{i}_labels.npy'\n",
    "        labels = np.load(label_path).reshape(-1).astype(np.int32)\n",
    "\n",
    "        # --- CSF ---\n",
    "        csf = CSF.CSF()\n",
    "        csf.params.bSloopSmooth = False\n",
    "        csf.params.cloth_resolution = 0.03\n",
    "        csf.params.rigidness = 1\n",
    "        csf.params.iterations = 500\n",
    "        csf.params.class_threshold = 0.1\n",
    "\n",
    "        csf.setPointCloud(xyz)\n",
    "        ground_idx = CSF.VecInt()\n",
    "        non_ground_idx = CSF.VecInt()\n",
    "        csf.do_filtering(ground_idx, non_ground_idx)\n",
    "\n",
    "        ground_idx = np.array(list(ground_idx), dtype=int)\n",
    "        obstacle_idx = np.array(list(non_ground_idx), dtype=int)\n",
    "\n",
    "        csf_labels = np.zeros_like(labels)\n",
    "        csf_labels[ground_idx] = 1\n",
    "        csf_labels[obstacle_idx] = 2\n",
    "\n",
    "        # --- KNN ---\n",
    "        k = 10\n",
    "        threshold = 0.7\n",
    "        labeled_idx = np.where(csf_labels != 0)[0]\n",
    "        unlabeled_idx = np.where(labels == 0)[0]\n",
    "\n",
    "        if labeled_idx.size > 0 and unlabeled_idx.size > 0:\n",
    "            knn = NearestNeighbors(n_neighbors=k).fit(xyz[labeled_idx])\n",
    "            _, neighbor_indices = knn.kneighbors(xyz[unlabeled_idx])\n",
    "            for j, neighbors in enumerate(neighbor_indices):\n",
    "                neighbor_labels = csf_labels[labeled_idx[neighbors]]\n",
    "                most_common, count = Counter(neighbor_labels).most_common(1)[0]\n",
    "                if count / k >= threshold:\n",
    "                    labels[unlabeled_idx[j]] = most_common\n",
    "\n",
    "        np.save(label_path, labels)\n",
    "\n",
    "        # # --- Assign colors and render to image ---\n",
    "        # label_to_color = {\n",
    "        #     0: (0.5, 0.5, 0.5),\n",
    "        #     1: (0.0, 1.0, 0.0),\n",
    "        #     2: (1.0, 0.0, 0.0),\n",
    "        # }\n",
    "        # colors = np.array([label_to_color.get(l, (0.5, 0.5, 0.5)) for l in labels])\n",
    "        # pcd.colors = o3d.utility.Vector3dVector(colors)\n",
    "\n",
    "        # vis = o3d.visualization.Visualizer()\n",
    "        # vis.create_window(visible=False)\n",
    "        # vis.add_geometry(pcd)\n",
    "        # vis.update_geometry(pcd)\n",
    "        # vis.poll_events()\n",
    "        # vis.update_renderer()\n",
    "        # vis.capture_screen_image(f\"{output_frame_dir}/{file_num}/frame_{frame_id:04d}.png\")\n",
    "        # vis.destroy_window()\n",
    "        # frame_id += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbe988ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "\n",
    "frame_dir = 'rendered_frames'\n",
    "file_num = 1\n",
    "frame_path = os.path.join(frame_dir, str(file_num))\n",
    "frame_files = sorted([f for f in os.listdir(frame_path) if f.endswith('.png')])\n",
    "\n",
    "if not frame_files:\n",
    "    raise ValueError(\"No frames found to create the video.\")\n",
    "\n",
    "# Read first image to determine size\n",
    "first_frame = cv2.imread(os.path.join(frame_path, frame_files[0]))\n",
    "height, width, _ = first_frame.shape\n",
    "out = cv2.VideoWriter('output_1.mp4', cv2.VideoWriter_fourcc(*'mp4v'), 5, (width, height))\n",
    "\n",
    "# Write all frames to video\n",
    "for frame_file in frame_files:\n",
    "    img = cv2.imread(os.path.join(frame_path, frame_file))\n",
    "    if img is not None:\n",
    "        out.write(img)\n",
    "\n",
    "out.release()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3913b7a8",
   "metadata": {},
   "source": [
    "# Label points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cca7f89b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.3.1 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"c:\\Users\\gavin\\.conda\\envs\\visual\\Lib\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"c:\\Users\\gavin\\.conda\\envs\\visual\\Lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"c:\\Users\\gavin\\.conda\\envs\\visual\\Lib\\site-packages\\ipykernel\\kernelapp.py\", line 739, in start\n",
      "    self.io_loop.start()\n",
      "  File \"c:\\Users\\gavin\\.conda\\envs\\visual\\Lib\\site-packages\\tornado\\platform\\asyncio.py\", line 211, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"c:\\Users\\gavin\\.conda\\envs\\visual\\Lib\\asyncio\\base_events.py\", line 645, in run_forever\n",
      "    self._run_once()\n",
      "  File \"c:\\Users\\gavin\\.conda\\envs\\visual\\Lib\\asyncio\\base_events.py\", line 1999, in _run_once\n",
      "    handle._run()\n",
      "  File \"c:\\Users\\gavin\\.conda\\envs\\visual\\Lib\\asyncio\\events.py\", line 88, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"c:\\Users\\gavin\\.conda\\envs\\visual\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 545, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"c:\\Users\\gavin\\.conda\\envs\\visual\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 534, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"c:\\Users\\gavin\\.conda\\envs\\visual\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 437, in dispatch_shell\n",
      "    await result\n",
      "  File \"c:\\Users\\gavin\\.conda\\envs\\visual\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 362, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"c:\\Users\\gavin\\.conda\\envs\\visual\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 778, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"c:\\Users\\gavin\\.conda\\envs\\visual\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 449, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"c:\\Users\\gavin\\.conda\\envs\\visual\\Lib\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"c:\\Users\\gavin\\.conda\\envs\\visual\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3098, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"c:\\Users\\gavin\\.conda\\envs\\visual\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3153, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"c:\\Users\\gavin\\.conda\\envs\\visual\\Lib\\site-packages\\IPython\\core\\async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"c:\\Users\\gavin\\.conda\\envs\\visual\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3362, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"c:\\Users\\gavin\\.conda\\envs\\visual\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3607, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"c:\\Users\\gavin\\.conda\\envs\\visual\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3667, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\gavin\\AppData\\Local\\Temp\\ipykernel_41456\\3873089367.py\", line 6, in <module>\n",
      "    import CSF\n",
      "  File \"c:\\Users\\gavin\\.conda\\envs\\visual\\Lib\\site-packages\\CSF.py\", line 15, in <module>\n",
      "    import _CSF\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "\nA module that was compiled using NumPy 1.x cannot be run in\nNumPy 2.3.1 as it may crash. To support both 1.x and 2.x\nversions of NumPy, modules must be compiled with NumPy 2.0.\nSome module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n\nIf you are a user of the module, the easiest solution will be to\ndowngrade to 'numpy<2' or try to upgrade the affected module.\nWe expect that some modules will need time to support NumPy 2.\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\gavin\\.conda\\envs\\visual\\Lib\\site-packages\\numpy\\core\\_multiarray_umath.py:46\u001b[39m, in \u001b[36m__getattr__\u001b[39m\u001b[34m(attr_name)\u001b[39m\n\u001b[32m     41\u001b[39m     \u001b[38;5;66;03m# Also print the message (with traceback).  This is because old versions\u001b[39;00m\n\u001b[32m     42\u001b[39m     \u001b[38;5;66;03m# of NumPy unfortunately set up the import to replace (and hide) the\u001b[39;00m\n\u001b[32m     43\u001b[39m     \u001b[38;5;66;03m# error.  The traceback shouldn't be needed, but e.g. pytest plugins\u001b[39;00m\n\u001b[32m     44\u001b[39m     \u001b[38;5;66;03m# seem to swallow it and we should be failing anyway...\u001b[39;00m\n\u001b[32m     45\u001b[39m     sys.stderr.write(msg + tb_msg)\n\u001b[32m---> \u001b[39m\u001b[32m46\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(msg)\n\u001b[32m     48\u001b[39m ret = \u001b[38;5;28mgetattr\u001b[39m(_multiarray_umath, attr_name, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m     49\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m ret \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[31mImportError\u001b[39m: \nA module that was compiled using NumPy 1.x cannot be run in\nNumPy 2.3.1 as it may crash. To support both 1.x and 2.x\nversions of NumPy, modules must be compiled with NumPy 2.0.\nSome module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n\nIf you are a user of the module, the easiest solution will be to\ndowngrade to 'numpy<2' or try to upgrade the affected module.\nWe expect that some modules will need time to support NumPy 2.\n\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "numpy.core.multiarray failed to import",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mopen3d\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mo3d\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mCSF\u001b[39;00m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mcv2\u001b[39;00m\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtqdm\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m tqdm\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\gavin\\.conda\\envs\\visual\\Lib\\site-packages\\CSF.py:15\u001b[39m\n\u001b[32m     13\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _CSF\n\u001b[32m     14\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m     \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m_CSF\u001b[39;00m\n\u001b[32m     17\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     18\u001b[39m     \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mbuiltins\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m__builtin__\u001b[39;00m\n",
      "\u001b[31mImportError\u001b[39m: numpy.core.multiarray failed to import"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "import open3d as o3d\n",
    "import numpy as np\n",
    "import CSF\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from collections import Counter\n",
    "\n",
    "def quat2rot(q):\n",
    "    qw, qx, qy, qz = q['w_val'], q['x_val'], q['y_val'], q['z_val']\n",
    "    return np.array([\n",
    "        [1-2*qy*qy-2*qz*qz,   2*qx*qy-2*qz*qw,     2*qx*qz+2*qy*qw],\n",
    "        [2*qx*qy+2*qz*qw,     1-2*qx*qx-2*qz*qz,   2*qy*qz-2*qx*qw],\n",
    "        [2*qx*qz-2*qy*qw,     2*qy*qz+2*qx*qw,     1-2*qx*qx-2*qy*qy]\n",
    "    ])\n",
    "\n",
    "def get_pose(state):\n",
    "    p = state['kinematics_estimated']['position']\n",
    "    o = state['kinematics_estimated']['orientation']\n",
    "    pos = np.array([p['x_val'], p['y_val'], p['z_val']], dtype=float)\n",
    "    return pos, quat2rot(o)\n",
    "\n",
    "def compute_labels_for_frame(track_path, frame_idx, threshold=1.2):\n",
    "    \"\"\"\n",
    "    Compute the 0/1/2 labels for frame `frame_idx` in folder `track_path`\n",
    "    using the same proximity + collision logic from your first script.\n",
    "    \"\"\"\n",
    "\n",
    "    # --- load point cloud & initial car pose (as before) ---\n",
    "    plyf   = os.path.join(track_path, f\"{frame_idx}.ply\")\n",
    "    car0f  = os.path.join(track_path, f\"{frame_idx}_car_state.json\")\n",
    "    coll0f = os.path.join(track_path, f\"{frame_idx}_collision_info.json\")\n",
    "    cloud = o3d.io.read_point_cloud(plyf)\n",
    "    pts   = np.asarray(cloud.points)                # shape (N,3)\n",
    "    car0  = json.load(open(car0f))\n",
    "    pos0, R0 = get_pose(car0)\n",
    "    world_pts = (R0 @ pts.T).T + pos0               # shape (N,3)\n",
    "\n",
    "    # --- build two Boolean masks across time (as before) ---\n",
    "    ever_close     = np.zeros(len(world_pts), dtype=bool)\n",
    "    ever_collision = np.zeros(len(world_pts), dtype=bool)\n",
    "    j = 1\n",
    "    while True:\n",
    "        carjf  = os.path.join(track_path, f\"{j}_car_state.json\")\n",
    "        colljf = os.path.join(track_path, f\"{j}_collision_info.json\")\n",
    "        if not (os.path.exists(carjf) and os.path.exists(colljf)):\n",
    "            break\n",
    "\n",
    "        carj  = json.load(open(carjf))\n",
    "        collj = json.load(open(colljf))\n",
    "        posj, _ = get_pose(carj)\n",
    "\n",
    "        # proximity mask\n",
    "        d_car = np.linalg.norm(world_pts - posj, axis=1)\n",
    "        ever_close |= (d_car < (threshold - 0.2))\n",
    "\n",
    "        # collision mask\n",
    "        if collj['has_collided']:\n",
    "            cp = collj['position']\n",
    "            pos_col = np.array([cp['x_val'], cp['y_val'], cp['z_val']], dtype=float)\n",
    "            d_col = np.linalg.norm(world_pts - pos_col, axis=1)\n",
    "            ever_collision |= (d_col < (threshold + 0.2))\n",
    "\n",
    "        j += 1\n",
    "    \n",
    "    labels = np.zeros(len(world_pts), dtype=np.uint8)\n",
    "    labels[ ever_close & ~ever_collision ] =1\n",
    "    labels[ ever_collision ] = 2\n",
    "    return labels\n",
    "# ——————— main processing loop ———————\n",
    "output_frame_dir = \"rendered_frames\"\n",
    "os.makedirs(output_frame_dir, exist_ok=True)\n",
    "\n",
    "data_root = \"../data\"\n",
    "threshold_check = 1.2   # or whatever you prefer\n",
    "k = 10                  # for KNN\n",
    "knn_thresh = 0.7        # for label propagation\n",
    "\n",
    "for file_num in tqdm(range(1), desc=\"Tracks\"):  # change upper bound as needed\n",
    "    track_folder = os.path.join(data_root, str(file_num))\n",
    "    names = os.listdir(track_folder)\n",
    "    ply_files = sorted(\n",
    "        [n for n in names if re.match(r\"^\\d+\\.ply$\", n)],\n",
    "        key=lambda x: int(x.split(\".\")[0])\n",
    "    )\n",
    "\n",
    "    for ply_name in tqdm(ply_files, desc=f\"Frames in track {file_num}\"):\n",
    "        idx = int(ply_name.split(\".\")[0])\n",
    "        # load point cloud\n",
    "        pcd = o3d.io.read_point_cloud(os.path.join(track_folder, ply_name))\n",
    "        xyz = np.asarray(pcd.points)\n",
    "\n",
    "        # --- compute labels on the fly instead of np.load(...) ---\n",
    "        labels = compute_labels_for_frame(track_folder, idx, threshold=threshold_check)\n",
    "        # labels are all zero\n",
    "        # labels = np.zeros(xyz.shape[0], dtype=np.int32) \n",
    "        # --- CSF ground/obstacle split ---\n",
    "        csf = CSF.CSF()\n",
    "        csf.params.bSloopSmooth = False\n",
    "        csf.params.cloth_resolution = 0.03\n",
    "        csf.params.rigidness = 1\n",
    "        csf.params.iterations = 500\n",
    "        csf.params.class_threshold = 0.1\n",
    "\n",
    "        csf.setPointCloud(xyz)\n",
    "        ground_idx = CSF.VecInt()\n",
    "        non_ground_idx = CSF.VecInt()\n",
    "        csf.do_filtering(ground_idx, non_ground_idx)\n",
    "\n",
    "        ground_idx = np.array(list(ground_idx), dtype=int)\n",
    "        obstacle_idx = np.array(list(non_ground_idx), dtype=int)\n",
    "\n",
    "        csf_labels = np.zeros_like(labels, dtype=np.int32)\n",
    "        csf_labels[ground_idx]  = 1\n",
    "        csf_labels[obstacle_idx] = 2\n",
    "\n",
    "        # --- KNN propagation to fill in any 0s ---\n",
    "        labeled_idx   = np.where(csf_labels != 0)[0]\n",
    "        unlabeled_idx = np.where(labels == 0)[0]\n",
    "\n",
    "        if labeled_idx.size and unlabeled_idx.size:\n",
    "            knn = NearestNeighbors(n_neighbors=k).fit(xyz[labeled_idx])\n",
    "            _, nbrs = knn.kneighbors(xyz[unlabeled_idx])\n",
    "            for j, neigh in enumerate(nbrs):\n",
    "                most_common, cnt = Counter(csf_labels[labeled_idx[neigh]]).most_common(1)[0]\n",
    "                if cnt / k >= knn_thresh:\n",
    "                    labels[unlabeled_idx[j]] = most_common\n",
    "\n",
    "        # out_npy = os.path.join(track_folder, f\"{idx}_labels.npy\")\n",
    "        # # print(out_npy)\n",
    "        # np.save(out_npy, labels)\n",
    "\n",
    "\n",
    "        colors = np.zeros_like(xyz)\n",
    "        colors[labels == 0] = [0.5, 0.5, 0.5]  # gray\\n\",\n",
    "        colors[labels == 1] = [0.0, 1.0, 0.0]  # green\\n\",\n",
    "        colors[labels == 2] = [1.0, 0.0, 0.0]  # red\\n\",\n",
    "        pcd.colors = o3d.utility.Vector3dVector(colors)\n",
    "\n",
    "        # attach to point cloud and visualize\n",
    "        pcd = o3d.geometry.PointCloud()\n",
    "        pcd.points = o3d.utility.Vector3dVector(xyz)\n",
    "        pcd.colors = o3d.utility.Vector3dVector(colors)\n",
    "\n",
    "        o3d.visualization.draw_geometries(\n",
    "            [pcd],\n",
    "            window_name=f\"Track {file_num} – Frame {idx}\",\n",
    "            width=800, height=600\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d3834f5",
   "metadata": {},
   "source": [
    "## csf 10 labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "944d0e0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Track 0:  97%|█████████▋| 30/31 [00:11<00:00,  2.78it/s]c:\\Users\\gavin\\.conda\\envs\\point\\lib\\site-packages\\ipykernel_launcher.py:109: RuntimeWarning: invalid value encountered in true_divide\n",
      "Track 0: 100%|██████████| 31/31 [00:11<00:00,  2.65it/s]\n",
      "Track 1: 100%|██████████| 146/146 [01:02<00:00,  2.34it/s]\n",
      "Track 2:  30%|██▉       | 408/1364 [05:22<11:23,  1.40it/s]c:\\Users\\gavin\\.conda\\envs\\point\\lib\\site-packages\\ipykernel_launcher.py:196: RuntimeWarning: invalid value encountered in true_divide\n",
      "Track 2: 100%|██████████| 1364/1364 [14:52<00:00,  1.53it/s]\n",
      "Track 3:  23%|██▎       | 102/437 [00:52<02:35,  2.16it/s]c:\\Users\\gavin\\.conda\\envs\\point\\lib\\site-packages\\numpy\\lib\\function_base.py:3968: RuntimeWarning: invalid value encountered in multiply\n",
      "  x2 = take(ap, indices_above, axis=axis) * weights_above\n",
      "Track 3: 100%|█████████▉| 436/437 [03:34<00:00,  2.72it/s]c:\\Users\\gavin\\.conda\\envs\\point\\lib\\site-packages\\ipykernel_launcher.py:196: RuntimeWarning: divide by zero encountered in true_divide\n",
      "Track 3: 100%|██████████| 437/437 [03:34<00:00,  2.04it/s]\n",
      "Track 4: 100%|██████████| 292/292 [02:11<00:00,  2.21it/s]\n",
      "Track 5: 100%|██████████| 45/45 [00:20<00:00,  2.21it/s]\n",
      "Track 6: 100%|██████████| 1171/1171 [11:13<00:00,  1.74it/s]\n",
      "Track 7: 100%|██████████| 1546/1546 [17:38<00:00,  1.46it/s]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "import open3d as o3d\n",
    "import numpy as np\n",
    "import CSF\n",
    "from tqdm import tqdm\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "from scipy.spatial import cKDTree\n",
    "def quat2rot(q):\n",
    "    qw, qx, qy, qz = q['w_val'], q['x_val'], q['y_val'], q['z_val']\n",
    "    return np.array([\n",
    "        [1-2*qy*qy-2*qz*qz,   2*qx*qy-2*qz*qw,     2*qx*qz+2*qy*qw],\n",
    "        [2*qx*qy+2*qz*qw,     1-2*qx*qx-2*qz*qz,   2*qy*qz-2*qx*qw],\n",
    "        [2*qx*qz-2*qy*qw,     2*qy*qz+2*qx*qw,     1-2*qx*qx-2*qy*qy]\n",
    "    ])\n",
    "\n",
    "def get_pose(state):\n",
    "    p = state['kinematics_estimated']['position']\n",
    "    o = state['kinematics_estimated']['orientation']\n",
    "    pos = np.array([p['x_val'], p['y_val'], p['z_val']], dtype=float)\n",
    "    return pos, quat2rot(o)\n",
    "\n",
    "from scipy.stats import rankdata\n",
    "\n",
    "def compute_merged_labels(track_path, frame_idx,\n",
    "                          quantile_weight=1/3,\n",
    "                          ttc_weight=1/3,\n",
    "                          smooth_weight=1/3,\n",
    "                          collision_radius=0.5,\n",
    "                          fps=10,\n",
    "                          smooth_alpha=1.0):\n",
    "    \"\"\"\n",
    "    Combines:\n",
    "      1) Quantile-based distance risk\n",
    "      2) Time-To-Collision (TTC) risk\n",
    "      3) Smooth distance+speed sigmoid risk\n",
    "    into a single 10-class label per point.\n",
    "\n",
    "    Points that actually collided get class=10.\n",
    "    \"\"\"\n",
    "    # --- load frame 0 and build world_pts array ---\n",
    "    plyf   = os.path.join(track_path, f\"{frame_idx}.ply\")\n",
    "    car0f  = os.path.join(track_path, f\"{frame_idx}_car_state.json\")\n",
    "    coll0f = os.path.join(track_path, f\"{frame_idx}_collision_info.json\")\n",
    "\n",
    "    cloud = o3d.io.read_point_cloud(plyf)\n",
    "    world_pts = np.asarray(cloud.points)\n",
    "\n",
    "    # get pose helper\n",
    "    def get_pose_from_file(json_f):\n",
    "        d = json.load(open(json_f))\n",
    "        return get_pose(d)  # returns (pos, R)\n",
    "\n",
    "    pos0, R0 = get_pose_from_file(car0f)\n",
    "    world_pts = (R0 @ world_pts.T).T + pos0\n",
    "\n",
    "    # --- gather car positions & collision flags over time ---\n",
    "    car_positions = [pos0]\n",
    "    collided_points = np.zeros(len(world_pts), dtype=bool)\n",
    "\n",
    "    j = frame_idx + 1\n",
    "    while True:\n",
    "        carjf  = os.path.join(track_path, f\"{j}_car_state.json\")\n",
    "        colljf = os.path.join(track_path, f\"{j}_collision_info.json\")\n",
    "        if not (os.path.exists(carjf) and os.path.exists(colljf)):\n",
    "            break\n",
    "\n",
    "        # car pose\n",
    "        pj, _ = get_pose_from_file(carjf)\n",
    "        car_positions.append(pj)\n",
    "\n",
    "        # mark any actual collisions\n",
    "        cj = json.load(open(colljf))\n",
    "        if cj.get('has_collided', False):\n",
    "            cp = cj['position']\n",
    "            pos_col = np.array([cp['x_val'], cp['y_val'], cp['z_val']], dtype=float)\n",
    "            d_col = np.linalg.norm(world_pts - pos_col, axis=1)\n",
    "            collided_points |= (d_col < 1.0)\n",
    "\n",
    "        j += 1\n",
    "\n",
    "    car_positions = np.stack(car_positions, axis=0)  # shape (T,3)\n",
    "    T = len(car_positions)\n",
    "\n",
    "    # --- 1) Quantile-based distance risk ---\n",
    "    # compute minimal distance to any car-centroid over time\n",
    "    dists = np.linalg.norm(\n",
    "        world_pts[None,:,:] - car_positions[:,None,:],\n",
    "        axis=2\n",
    "    )  # shape (T, N_pts)\n",
    "    min_dists = dists.min(axis=0)\n",
    "\n",
    "    # Convert to a [0,1] score where farthest points = 0, closest = 1\n",
    "    # via rank percentile\n",
    "    ranks = rankdata(min_dists, method='dense') - 1\n",
    "    quantile_score = 1 - (ranks / ranks.max())\n",
    "\n",
    "    # --- 2) Time-to-collision (TTC) risk ---\n",
    "    max_ttc = (T-1)/fps\n",
    "    ttc = np.full(len(world_pts), max_ttc, dtype=float)\n",
    "\n",
    "    for frame_idx_j, pj in enumerate(car_positions):\n",
    "        d = np.linalg.norm(world_pts - pj, axis=1)\n",
    "        entering = (d < collision_radius) & (ttc > frame_idx_j/fps)\n",
    "        ttc[entering] = frame_idx_j / fps\n",
    "\n",
    "    # normalize so that soonest collisions = 1, no collision = 0\n",
    "    ttc_score = 1 - (ttc / max_ttc)\n",
    "\n",
    "    # --- 3) Smooth distance+speed sigmoid risk ---\n",
    "    smooth_risks = np.zeros((T-1, len(world_pts)), dtype=float)\n",
    "    for j in range(T-1):\n",
    "        pj, pj1 = car_positions[j], car_positions[j+1]\n",
    "        v = pj1 - pj\n",
    "        norm_v = np.linalg.norm(v) + 1e-6\n",
    "        rel = world_pts - pj  # vector from car to points\n",
    "        approach_speed = np.abs((rel * v).sum(axis=1)) / norm_v\n",
    "        d = np.linalg.norm(rel, axis=1) + 1e-6\n",
    "        raw = approach_speed / d\n",
    "        # logistic centered at raw=1\n",
    "        smooth_risks[j] = 1 / (1 + np.exp(-smooth_alpha * (raw - 1)))\n",
    "    car_positions = np.stack(car_positions, axis=0)\n",
    "    T = len(car_positions)\n",
    "\n",
    "    # if no future frames, return quantile‐only labels\n",
    "    if T < 2:\n",
    "        # your min_dists calculated below will be based on the single pose\n",
    "        dists      = np.linalg.norm(world_pts[None,:,:] - car_positions[:,None,:], axis=2)\n",
    "        min_dists  = dists.min(axis=0)\n",
    "        ranks      = rankdata(min_dists, method='dense') - 1\n",
    "        q_score    = 1 - (ranks / ranks.max())\n",
    "        labels     = np.ceil(q_score * 10).astype(int)\n",
    "        return np.clip(labels, 1, 10)\n",
    "    smooth_score = smooth_risks.max(axis=0)\n",
    "\n",
    "    # --- combine the three risk scores ---\n",
    "    combined = (\n",
    "        quantile_weight * quantile_score +\n",
    "        ttc_weight      * ttc_score +\n",
    "        smooth_weight   * smooth_score\n",
    "    )\n",
    "\n",
    "    # convert to 1–10 integer labels\n",
    "    labels = np.ceil(combined * 10).astype(int)\n",
    "    labels = np.clip(labels, 1, 10)\n",
    "\n",
    "    # override actual collisions\n",
    "    labels[collided_points] = 10\n",
    "\n",
    "    return labels\n",
    "\n",
    "# custom colormap for final visualization\n",
    "colors = [(0.5, 0.5, 0.5), (1,1,0), (1,0,0)]\n",
    "custom_cmap = LinearSegmentedColormap.from_list(\"gray_yellow_red\", colors, N=10)\n",
    "\n",
    "# MAIN\n",
    "data_root = \"../data\"\n",
    "output_frame_dir = \"rendered_frames\"\n",
    "os.makedirs(output_frame_dir, exist_ok=True)\n",
    "threshold_check = 1.2\n",
    "\n",
    "for track_id in range(8):\n",
    "    track_folder = os.path.join(data_root, str(track_id))\n",
    "    ply_files = sorted(\n",
    "        [f for f in os.listdir(track_folder) if re.match(r\"^\\d+\\.ply$\", f)],\n",
    "        key=lambda x: int(x.split('.')[0])\n",
    "    )\n",
    "\n",
    "    for ply_name in tqdm(ply_files, desc=f\"Track {track_id}\"):\n",
    "        idx = int(ply_name.split('.')[0])\n",
    "\n",
    "        # 1) load raw points\n",
    "        pcd = o3d.io.read_point_cloud(os.path.join(track_folder, ply_name))\n",
    "        xyz = np.asarray(pcd.points)\n",
    "\n",
    "        # 2) CSF ground vs non-ground\n",
    "        csf = CSF.CSF()\n",
    "        csf.params.bSloopSmooth     = False\n",
    "        csf.params.cloth_resolution = 0.03\n",
    "        csf.params.rigidness        = 1\n",
    "        csf.params.iterations       = 500\n",
    "        csf.params.class_threshold  = 0.1\n",
    "        csf.setPointCloud(xyz)\n",
    "\n",
    "        ground_csfi     = CSF.VecInt()\n",
    "        non_ground_csfi = CSF.VecInt()\n",
    "        csf.do_filtering(ground_csfi, non_ground_csfi)\n",
    "        obstacle_idx = np.array(list(non_ground_csfi), dtype=int)\n",
    "        ground_idx   = np.array(list(ground_csfi),     dtype=int)\n",
    "\n",
    "        # 3) static-distance labels (1–9 + 10 for obstacles)\n",
    "        tree = cKDTree(xyz[obstacle_idx])\n",
    "        dist_to_obs, _ = tree.query(xyz, k=1)\n",
    "        max_d      = np.percentile(dist_to_obs, 90)\n",
    "        normalized = np.clip(dist_to_obs / max_d * 9, 0, 9)\n",
    "        yn_labels  = np.ceil((9 - normalized) / 1).astype(int)\n",
    "        yn_labels  = np.clip(yn_labels, 1, 9)\n",
    "        yn_labels[obstacle_idx] = 10\n",
    "\n",
    "        # 4) dynamic-future labels from compute_labels_for_frame (1–10)\n",
    "        dyn_labels = compute_merged_labels(track_folder, idx)\n",
    "\n",
    "        # 5) combine per-point:\n",
    "        #    by default average the two;\n",
    "        #    but if *either* label is 10, force combined = 10\n",
    "        combined = (dyn_labels+ yn_labels ) //2\n",
    "        mask10   = (dyn_labels == 10) | (yn_labels == 10)\n",
    "        combined[mask10] = 10\n",
    "        dyn_only = (dyn_labels == 10) & (yn_labels != 10)\n",
    "        combined[dyn_only] = np.ceil((dyn_labels[dyn_only] + yn_labels[dyn_only]) / 2).astype(int)\n",
    "\n",
    "        out_npy = os.path.join(track_folder, f\"{idx}_labels_2.npy\")\n",
    "        # print(out_npy)\n",
    "        np.save(out_npy, combined)\n",
    "\n",
    "        # 6) visualize combined label\n",
    "        # norm_comb = (combined - 1) / 9.0        # maps 1→0.0 … 10→1.0\n",
    "        # rgb       = custom_cmap(norm_comb)[:, :3]\n",
    "\n",
    "        # vis_pcd = o3d.geometry.PointCloud()\n",
    "        # vis_pcd.points = o3d.utility.Vector3dVector(xyz)\n",
    "        # vis_pcd.colors = o3d.utility.Vector3dVector(rgb)\n",
    "\n",
    "        # o3d.visualization.draw_geometries(\n",
    "        #     [vis_pcd],\n",
    "        #     window_name=f\"Track {track_id} – Frame {idx}\",\n",
    "        #     width=800, height=600\n",
    "        # )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be91fd2c",
   "metadata": {},
   "source": [
    "### Visualize and captyure as IMage\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5c96a679",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Frame in track 0: 100%|██████████| 31/31 [00:00<00:00, 39.35it/s]\n",
      "Frame in track 1: 100%|██████████| 146/146 [00:04<00:00, 31.15it/s]\n",
      "Frame in track 2: 100%|██████████| 1364/1364 [00:56<00:00, 24.17it/s]\n",
      "Frame in track 3: 100%|██████████| 437/437 [00:17<00:00, 24.63it/s]\n",
      "Frame in track 4: 100%|██████████| 292/292 [00:11<00:00, 24.94it/s]\n",
      "Frame in track 5: 100%|██████████| 45/45 [00:01<00:00, 25.46it/s]\n",
      "Frame in track 6: 100%|██████████| 1171/1171 [00:48<00:00, 23.95it/s]\n",
      "Frame in track 7: 100%|██████████| 1546/1546 [01:01<00:00, 25.07it/s]\n",
      "Tracks: 100%|██████████| 8/8 [03:24<00:00, 25.54s/it]\n"
     ]
    }
   ],
   "source": [
    "import open3d as o3d\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "from scipy.spatial.transform import Rotation as R\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "import os\n",
    "\n",
    "import json\n",
    "import open3d as o3d\n",
    "import numpy as np\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def quat2rot(q):\n",
    "    qw, qx, qy, qz = q['w_val'], q['x_val'], q['y_val'], q['z_val']\n",
    "    return np.array([\n",
    "        [1-2*qy*qy-2*qz*qz,   2*qx*qy-2*qz*qw,     2*qx*qz+2*qy*qw],\n",
    "        [2*qx*qy+2*qz*qw,     1-2*qx*qx-2*qz*qz,   2*qy*qz-2*qx*qw],\n",
    "        [2*qx*qz-2*qy*qw,     2*qy*qz+2*qx*qw,     1-2*qx*qx-2*qy*qy]\n",
    "    ])\n",
    "\n",
    "def get_pose(state):\n",
    "    p = state['kinematics_estimated']['position']\n",
    "    o = state['kinematics_estimated']['orientation']\n",
    "    pos = np.array([p['x_val'], p['y_val'], p['z_val']], dtype=float)\n",
    "    return pos, quat2rot(o)\n",
    "\n",
    "output_frame_dir = \"rendered_frames\"\n",
    "os.makedirs(output_frame_dir, exist_ok=True)\n",
    "\n",
    "# --- build car mesh ---\n",
    "car_mesh = o3d.geometry.TriangleMesh.create_box(width=0.8, height=0.4, depth=0.3)\n",
    "car_mesh.compute_vertex_normals()\n",
    "car_mesh.paint_uniform_color([0.0, 0.0, 0.0])        # red car\n",
    "center = car_mesh.get_center()\n",
    "car_mesh.translate(-center)\n",
    "\n",
    "# --- build a front arrow ---\n",
    "arrow = o3d.geometry.TriangleMesh.create_arrow(\n",
    "    cylinder_radius=0.03,    # shaft thickness\n",
    "    cone_radius=0.06,        # tip thickness\n",
    "    cylinder_height=0.2,     # shaft length\n",
    "    cone_height=0.1          # tip length\n",
    ")\n",
    "arrow.compute_vertex_normals()\n",
    "arrow.paint_uniform_color([1.0, 0.0, 0.0])   # make it bright red\n",
    "\n",
    "# default arrow points along +Z, so rotate it to point along +X\n",
    "\n",
    "R_y_neg90 = R.from_euler('y', -np.pi/2).as_matrix()\n",
    "arrow.rotate(R_y_neg90, center=(0,0,0))\n",
    "arrow.translate([0.2, 0, 0.5])\n",
    "# # custom colormap for final visualization\n",
    "colors = [(0.5, 0.5, 0.5), (1,1,0), (1,0,0)]\n",
    "custom_cmap = LinearSegmentedColormap.from_list(\"gray_yellow_red\", colors, N=10)\n",
    "for file_num in tqdm(range(8), desc=\"Tracks\"):\n",
    "    file_output_dir = os.path.join(output_frame_dir, str(file_num))\n",
    "    os.makedirs(file_output_dir, exist_ok=True)\n",
    "\n",
    "    data_dir = f'../data/{file_num}'\n",
    "    ply_files = sorted([f for f in os.listdir(data_dir) if f.endswith('.ply')],\n",
    "                       key=lambda x: int(x[:-4]))\n",
    "\n",
    "    # one window per track\n",
    "    vis = o3d.visualization.Visualizer()\n",
    "    vis.create_window(width=1280, height=720, visible=False)\n",
    "\n",
    "    ctr = vis.get_view_control()\n",
    "    \n",
    "    for ply_name in tqdm(ply_files, desc=f\"Frame in track {file_num}\"):\n",
    "        idx = ply_name[:-4]\n",
    "\n",
    "        # --- load\n",
    "        pcd = o3d.io.read_point_cloud(os.path.join(data_dir, ply_name))\n",
    "        labels = np.load(os.path.join(data_dir, f\"{idx}_labels_2.npy\")).astype(int).reshape(-1)\n",
    "        with open(os.path.join(data_dir, f\"{idx}_car_state.json\")) as f:\n",
    "            car_state = json.load(f)\n",
    "\n",
    "        # --- colorize\n",
    "        norm_comb = (labels - 1) / 9.0        # maps 1→0.0 … 10→1.0\n",
    "        cols       = custom_cmap(norm_comb)[:, :3]\n",
    "        # cols = np.array([label_to_color.get(l, label_to_color[0]) for l in labels])\n",
    "        pcd.colors = o3d.utility.Vector3dVector(cols)\n",
    "        mirror_x = np.eye(4)\n",
    "        mirror_x[0, 0] = -1.0\n",
    "        pcd.transform(mirror_x)\n",
    "\n",
    "        # --- get pose & flatten to yaw only\n",
    "        pos, rot_full = get_pose(car_state)\n",
    "        pos[0] *= -1  # mirror X\n",
    "        rot_full = np.diag([-1, 1, 1]) @ rot_full  # mirror orientation\n",
    "\n",
    "        yaw = np.arctan2(rot_full[1, 0], rot_full[0, 0])\n",
    "        rot_flat = R.from_euler('z', yaw, degrees=False).as_matrix()\n",
    "\n",
    "        # --- chase‐cam in flattened frame\n",
    "        offset_local = np.array([-7, 0, -5.0])\n",
    "        lookat = car_mesh.get_center() + np.array([0.0, 0.0, 0.95])\n",
    "        cam_pos = car_mesh.get_center() + ( offset_local)\n",
    "\n",
    "        # --- render\n",
    "        vis.clear_geometries()\n",
    "        vis.add_geometry(pcd)\n",
    "        vis.add_geometry(car_mesh)  \n",
    "        vis.add_geometry(arrow)\n",
    "        ctr.set_lookat( lookat )\n",
    "        front = (lookat - cam_pos)\n",
    "        front /= np.linalg.norm(front)\n",
    "        ctr.set_front( front.tolist() )\n",
    "        ctr.set_up([0, 0, 1])\n",
    "        ctr.set_zoom(0.4)\n",
    "\n",
    "        vis.poll_events()\n",
    "        vis.update_renderer()\n",
    "        # vis.run()\n",
    "        # time.sleep(0.1)\n",
    "        img_path = os.path.join(file_output_dir, f\"{idx}.png\")\n",
    "        vis.capture_screen_image(img_path)\n",
    "\n",
    "    vis.destroy_window()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6241899d",
   "metadata": {},
   "source": [
    "Make video "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "25767a24",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Making videos:  12%|█▎        | 1/8 [00:00<00:04,  1.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " → Saved video: videos\\track_0.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Making videos:  25%|██▌       | 2/8 [00:03<00:11,  1.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " → Saved video: videos\\track_1.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Making videos:  38%|███▊      | 3/8 [00:30<01:05, 13.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " → Saved video: videos\\track_2.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Making videos:  50%|█████     | 4/8 [00:38<00:45, 11.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " → Saved video: videos\\track_3.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Making videos:  62%|██████▎   | 5/8 [00:44<00:28,  9.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " → Saved video: videos\\track_4.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Making videos:  75%|███████▌  | 6/8 [00:45<00:13,  6.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " → Saved video: videos\\track_5.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Making videos:  88%|████████▊ | 7/8 [01:08<00:11, 11.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " → Saved video: videos\\track_6.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Making videos: 100%|██████████| 8/8 [01:40<00:00, 12.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " → Saved video: videos\\track_7.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "\n",
    "# folders\n",
    "frame_folder       = 'rendered_frames'   # where your point images live, in subfolders 0,1,...,7\n",
    "camera_pic_folder  = '../data'           # where your camera images live, same subfolder structure\n",
    "output_folder      = 'videos'            # where the .mp4 files will be written\n",
    "\n",
    "# make sure output_folder exists\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# parameters\n",
    "fps = 30  # frames per second for the output video\n",
    "\n",
    "def resize_to_height(img, target_h):\n",
    "    h, w = img.shape[:2]\n",
    "    scale = target_h / float(h)\n",
    "    return cv2.resize(img, (int(w * scale), target_h))\n",
    "\n",
    "for track_id in tqdm(range(8), desc=\"Making videos\"):\n",
    "    cam_dir   = os.path.join(camera_pic_folder,  str(track_id))\n",
    "    point_dir = os.path.join(frame_folder,       str(track_id))\n",
    "    \n",
    "    # collect and sort PNGs by numeric name (e.g. \"0.png\", \"1.png\", ...)\n",
    "    files = sorted(\n",
    "        [f for f in os.listdir(cam_dir) if f.lower().endswith('.png')],\n",
    "        key=lambda fn: int(os.path.splitext(fn)[0])\n",
    "    )\n",
    "    if not files:\n",
    "        print(f\" → no images in {cam_dir}, skipping\")\n",
    "        continue\n",
    "\n",
    "    # load first pair to determine output size\n",
    "    p0 = cv2.imread(os.path.join(point_dir, files[0]))\n",
    "    c0 = cv2.imread(os.path.join(cam_dir,   files[0]))\n",
    "    if p0 is None or c0 is None:\n",
    "        raise RuntimeError(f\"Could not read {files[0]} from one of the folders\")\n",
    "\n",
    "    # match heights\n",
    "    H = max(p0.shape[0], c0.shape[0])\n",
    "    p0 = resize_to_height(p0, H)\n",
    "    c0 = resize_to_height(c0, H)\n",
    "\n",
    "    # setup video writer\n",
    "    W = p0.shape[1] + c0.shape[1]\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    out_path = os.path.join(output_folder, f'track_{track_id}.mp4')\n",
    "    writer = cv2.VideoWriter(out_path, fourcc, fps, (W, H))\n",
    "    \n",
    "    # write first frame\n",
    "    writer.write(cv2.hconcat([p0, c0]))\n",
    "\n",
    "    # process remaining frames\n",
    "    for fname in files[1:]:\n",
    "        p = cv2.imread(os.path.join(point_dir, fname))\n",
    "        c = cv2.imread(os.path.join(cam_dir,   fname))\n",
    "        if p is None or c is None:\n",
    "            print(f\"  ✗ skipping {fname} (failed to load)\")\n",
    "            continue\n",
    "        p = resize_to_height(p, H)\n",
    "        c = resize_to_height(c, H)\n",
    "        writer.write(cv2.hconcat([p, c]))\n",
    "\n",
    "    writer.release()\n",
    "    print(f\" → Saved video: {out_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d687e13d",
   "metadata": {},
   "source": [
    "-------------------------------------"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "point",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
