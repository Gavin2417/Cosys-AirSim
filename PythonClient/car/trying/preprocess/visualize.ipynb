{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e021412d",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcluster\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m KMeans\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m  \u001b[39m\u001b[34;01mopen3d\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mo3d\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'sklearn'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "import  open3d as o3d\n",
    "import numpy as np\n",
    "import open3d as o3d\n",
    "import os\n",
    "import re\n",
    "file_num = 0\n",
    "\n",
    "# Example data (replace with actual point cloud and initial labels)\n",
    "# load points and labels\n",
    "label_to_color = {\n",
    "        0: (0.0, 0.0, 0.0),\n",
    "        1: (0.0, 1.0, 0.0),\n",
    "        2: (1.0, 0.0, 0.0),\n",
    "    }\n",
    "for file_num in range(8):\n",
    "    names = os.listdir(f'../data/{file_num}')\n",
    "    pattern_ply = re.compile(r'^[^\\.]+\\.ply$')\n",
    "    names_ply = [n for n in names if pattern_ply.match(n)]\n",
    "    for i in range(1, len(names_ply) + 1):\n",
    "        pc_path = f'../data/{file_num}/{i}.ply'  # replace with your point cloud file\n",
    "        label_path = f'../data/{file_num}/{i}_labels.npy'  # replace with your label file\n",
    "        pcd = o3d.io.read_point_cloud(pc_path)\n",
    "        points = np.asarray(pcd.points)        # shape (N, 3)\n",
    "        labels = np.load(label_path).reshape(-1).astype(np.int32)# 1 = safe, 0 = unsafe, -1 = unlabeled\n",
    "\n",
    "        # Apply K-Means clustering to all points\n",
    "        K = 25 # for example, 15 clusters (tune this as needed)\n",
    "        kmeans = KMeans(n_clusters=K, random_state=42)\n",
    "        cluster_ids = kmeans.fit_predict(points)\n",
    "\n",
    "        # Determine majority label in each cluster\n",
    "        cluster_label = {}  # map cluster_id -> assigned label\n",
    "        for cid in range(K):\n",
    "            idx = np.where(cluster_ids == cid)[0]               # indices of points in this cluster\n",
    "            labeled_idx = idx[labels[idx] != -1]                # indices of labeled points in cluster\n",
    "            if labeled_idx.size == 0:\n",
    "                continue  # no label info in this cluster; skip assigning\n",
    "            # Count safe vs unsafe among known labels in cluster\n",
    "            safe_count = np.sum(labels[labeled_idx] == 1)\n",
    "            unsafe_count = np.sum(labels[labeled_idx] == 2)\n",
    "            # Decide label if one class dominates\n",
    "            total_labeled = safe_count + unsafe_count\n",
    "            if total_labeled > 0:\n",
    "                majority_label = 1 if safe_count > unsafe_count else 2\n",
    "                frac = max(safe_count, unsafe_count) / total_labeled\n",
    "                # print(f\"Cluster {cid} - Safe: {safe_count}, Unsafe: {unsafe_count}, Fraction: {frac:.2f}\")\n",
    "                if frac >= 0.70:  # e.g., require at least 70% agreement\n",
    "                    cluster_label[cid] = majority_label\n",
    "        # Assign labels to unlabeled points based on cluster majority\n",
    "        new_labels = labels.copy()\n",
    "        for cid, lbl in cluster_label.items():\n",
    "            # print(f\"Cluster {cid} majority label: {lbl}\")\n",
    "            # print(f\"Cluster {cid} majority label: {lbl}\")\n",
    "            idx = np.where(cluster_ids == cid)[0]\n",
    "            # Label only those that were unlabeled\n",
    "            unl_idx = idx[new_labels[idx] == 0]\n",
    "        #     new_labels[unl_idx] = lbl\n",
    "        # # save the new labels\n",
    "        # print(\"Total number oif pints\", len(new_labels)-len(labels))\n",
    "        # print(f\"number of zero label before the point cloud: {np.sum(new_labels == 0)- np.sum(labels == 0)}\")\n",
    "        np.save(f'../data/{file_num}/{i}_labels.npy', new_labels)\n",
    "        print(\"done \", file_num)\n",
    "    # print(f\"number of zero label after the point cloud: {np.sum(new_labels == 0)}\")\n",
    "    # # 'new_labels' now contains expanded labels for points that met the criteria\n",
    "    # print(\"unique labels after clustering:\", np.unique(new_labels))\n",
    "    # # visualize the results\n",
    "    # pcd.colors = o3d.utility.Vector3dVector(np.array([label_to_color[l] for l in new_labels], dtype=np.float64))\n",
    "    # o3d.visualization.draw_geometries([pcd])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d44c2dc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import open3d as o3d\n",
    "import os\n",
    "import re\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from collections import Counter\n",
    "\n",
    "label_to_color = {\n",
    "    0: (0.0, 0.0, 0.0),\n",
    "    1: (0.0, 1.0, 0.0),\n",
    "    2: (1.0, 0.0, 0.0),\n",
    "}\n",
    "\n",
    "k = 50  # Number of neighbors\n",
    "threshold = 0.4  # 70% majority required to assign label\n",
    "\n",
    "for file_num in range(8):\n",
    "    names = os.listdir(f'../data/{file_num}')\n",
    "    pattern_ply = re.compile(r'^[^\\.]+\\.ply$')\n",
    "    names_ply = [n for n in names if pattern_ply.match(n)]\n",
    "    \n",
    "    for i in range(1, len(names_ply) + 1):\n",
    "        pc_path = f'../data/{file_num}/{i}.ply'\n",
    "        label_path = f'../data/{file_num}/{i}_labels.npy'\n",
    "        \n",
    "        pcd = o3d.io.read_point_cloud(pc_path)\n",
    "        points = np.asarray(pcd.points)\n",
    "        labels = np.load(label_path).reshape(-1).astype(np.int32)\n",
    "\n",
    "        labeled_idx = np.where((labels == 1) | (labels == 2))[0]\n",
    "        unlabeled_idx = np.where(labels == 0)[0]\n",
    "\n",
    "        if labeled_idx.size == 0 or unlabeled_idx.size == 0:\n",
    "            continue\n",
    "\n",
    "        labeled_points = points[labeled_idx]\n",
    "        unlabeled_points = points[unlabeled_idx]\n",
    "        labeled_labels = labels[labeled_idx]\n",
    "\n",
    "        nbrs = NearestNeighbors(n_neighbors=k, algorithm='auto').fit(labeled_points)\n",
    "        distances, indices = nbrs.kneighbors(unlabeled_points)\n",
    "\n",
    "        new_labels = labels.copy()\n",
    "\n",
    "        for j, neighbor_idxs in enumerate(indices):\n",
    "            neighbor_labels = labeled_labels[neighbor_idxs]\n",
    "            label_counts = Counter(neighbor_labels)\n",
    "            most_common_label, count = label_counts.most_common(1)[0]\n",
    "            if count / k >= threshold:\n",
    "                new_labels[unlabeled_idx[j]] = most_common_label\n",
    "\n",
    "        # np.save(f'../data/{file_num}/{i}_labels.npy', new_labels)\n",
    "        # print(\"Done:\", file_num, i)\n",
    "        # Map labels to colors (make sure the label_to_color dictionary is defined)\n",
    "        colors = np.array([label_to_color.get(lbl, (0.5, 0.5, 0.5)) for lbl in new_labels], dtype=np.float64)\n",
    "        pcd.colors = o3d.utility.Vector3dVector(colors)\n",
    "        o3d.visualization.draw_geometries([pcd], window_name=f\"Point Cloud {file_num}-{i}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b067ec7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-d6eeb72d1c4e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m         \u001b[1;31m# 5) Visualize\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 42\u001b[1;33m         \u001b[0mo3d\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvisualization\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdraw_geometries\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mground_pc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobstacle_pc\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import open3d as o3d\n",
    "import CSF\n",
    "import os, re\n",
    "# ---- your existing setup ----\n",
    "# file_num = 0\n",
    "# i = 5\n",
    "for file_num in range(8):\n",
    "    file_num =7\n",
    "    names = os.listdir(f'../data/{file_num}')\n",
    "    pattern_ply = re.compile(r'^[^\\.]+\\.ply$')\n",
    "    names_ply = [n for n in names if pattern_ply.match(n)]\n",
    "    for i in range(1, len(names_ply) + 1):\n",
    "        pcd = o3d.io.read_point_cloud(f'../data/{file_num}/{i}.ply')\n",
    "        xyz = np.asarray(pcd.points)\n",
    "\n",
    "        # 2) Configure the CSF filter\n",
    "        csf = CSF.CSF()\n",
    "        csf.params.bSloopSmooth    = False    # smooth out small terrain noise\n",
    "        csf.params.cloth_resolution = 0.03    # size of cloth mesh cells (m)\n",
    "        # (optional) tweak these too:\n",
    "        csf.params.rigidness    = 1\n",
    "        csf.params.iterations   = 500\n",
    "        csf.params.class_threshold = 0.1\n",
    "\n",
    "        # 3) Run the filter\n",
    "        csf.setPointCloud(xyz)\n",
    "        ground_idx     = CSF.VecInt()       # will hold indices of ground points\n",
    "        non_ground_idx = CSF.VecInt()       # will hold indices of obstacles\n",
    "        csf.do_filtering(ground_idx, non_ground_idx)\n",
    "\n",
    "        # 4) Extract and color\n",
    "        ground_pts   = xyz[np.array(list(ground_idx),     dtype=int)]\n",
    "        obstacle_pts = xyz[np.array(list(non_ground_idx), dtype=int)]\n",
    "        ground_pc     = o3d.geometry.PointCloud(o3d.utility.Vector3dVector(ground_pts))\n",
    "        obstacle_pc   = o3d.geometry.PointCloud(o3d.utility.Vector3dVector(obstacle_pts))\n",
    "\n",
    "        ground_pc.paint_uniform_color([0.0, 1.0, 0.0])   # gray = ground\n",
    "        obstacle_pc.paint_uniform_color([1.0, 0.0, 0.0]) # red  = obstacles\n",
    "\n",
    "        # 5) Visualize\n",
    "        o3d.visualization.draw_geometries([ground_pc, obstacle_pc])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5188a7c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-94f693d6496b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     69\u001b[0m             \u001b[0mwidth\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m800\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     70\u001b[0m             \u001b[0mheight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m600\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 71\u001b[1;33m             \u001b[0mmesh_show_back_face\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     72\u001b[0m         )\n\u001b[0;32m     73\u001b[0m         \u001b[1;31m# visua;oze\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import open3d as o3d\n",
    "import CSF\n",
    "\n",
    "BASE_DIR = '../data'\n",
    "SLOPE_THRESHOLD_DEG = 10.0   # ramp if normal deviates more than this from vertical\n",
    "\n",
    "for file_num in range(8):\n",
    "    file_num =7\n",
    "    folder = os.path.join(BASE_DIR, str(file_num))\n",
    "    if not os.path.isdir(folder):\n",
    "        continue\n",
    "\n",
    "    ply_files = sorted(f for f in os.listdir(folder) if f.lower().endswith('.ply'))\n",
    "    for ply_name in ply_files:\n",
    "        # 1) load\n",
    "        ply_path = os.path.join(folder, ply_name)\n",
    "        pcd = o3d.io.read_point_cloud(ply_path)\n",
    "        xyz = np.asarray(pcd.points)\n",
    "\n",
    "        # 2) estimate normals once on full cloud\n",
    "        pcd.estimate_normals(search_param=o3d.geometry.KDTreeSearchParamKNN(knn=30))\n",
    "        normals = np.asarray(pcd.normals)  # shape (N,3)\n",
    "\n",
    "        # 3) run CSF\n",
    "        csf = CSF.CSF()\n",
    "        csf.params.bSloopSmooth     = True\n",
    "        csf.params.cloth_resolution = 0.1\n",
    "        csf.params.rigidness        = 5\n",
    "        csf.params.iterations       = 500\n",
    "        csf.params.class_threshold  = 0.5\n",
    "\n",
    "        csf.setPointCloud(xyz)\n",
    "        ground_idx     = CSF.VecInt()\n",
    "        non_ground_idx = CSF.VecInt()\n",
    "        csf.do_filtering(ground_idx, non_ground_idx)\n",
    "\n",
    "        # convert to Python lists\n",
    "        ground_idx_list     = np.array(list(ground_idx), dtype=int)\n",
    "        non_ground_idx_list = np.array(list(non_ground_idx), dtype=int)\n",
    "\n",
    "        # 4) detect ramps in the ground set\n",
    "        g_normals = normals[ground_idx_list]                   # normals for CSF‐ground\n",
    "        # angle from vertical = arccos(|n·[0,0,1]|)\n",
    "        angles = np.degrees(np.arccos(np.clip(np.abs(g_normals[:,2]), -1.0, 1.0)))\n",
    "        ramp_mask = angles > SLOPE_THRESHOLD_DEG\n",
    "\n",
    "        ramp_idx_global = ground_idx_list[ramp_mask]           # these are the ramps\n",
    "        flat_idx_global = ground_idx_list[~ramp_mask]          # truly flat ground\n",
    "\n",
    "        # 5) assemble final indices\n",
    "        final_ground_idx   = flat_idx_global\n",
    "        final_obstacle_idx = np.concatenate([non_ground_idx_list, ramp_idx_global])\n",
    "\n",
    "        # 6) extract point clouds\n",
    "        ground_pc   = o3d.geometry.PointCloud(o3d.utility.Vector3dVector(xyz[final_ground_idx]))\n",
    "        obstacle_pc = o3d.geometry.PointCloud(o3d.utility.Vector3dVector(xyz[final_obstacle_idx]))\n",
    "\n",
    "        # color: green=flat ground, blue=ramps, red=other obstacles\n",
    "        ground_pc.paint_uniform_color([0.0, 1.0, 0.0])\n",
    "        # optionally visualize ramps separately:\n",
    "        ramp_pc = o3d.geometry.PointCloud(o3d.utility.Vector3dVector(xyz[ramp_idx_global]))\n",
    "        ramp_pc.paint_uniform_color([0.0, 0.0, 1.0])\n",
    "        obstacle_pc.paint_uniform_color([1.0, 0.0, 0.0])\n",
    "        o3d.visualization.draw_geometries(\n",
    "            [ground_pc, ramp_pc, obstacle_pc],\n",
    "            window_name=f\"Segmentation: {ply_name}\",\n",
    "            width=800,\n",
    "            height=600,\n",
    "            mesh_show_back_face=True\n",
    "        )\n",
    "        # visua;oze \n",
    "        # # 7) write or visualize\n",
    "        # o3d.io.write_point_cloud(os.path.join(folder, ply_name.replace('.ply','_flat.ply')),   ground_pc)\n",
    "        # o3d.io.write_point_cloud(os.path.join(folder, ply_name.replace('.ply','_ramp.ply')),   ramp_pc)\n",
    "        # o3d.io.write_point_cloud(os.path.join(folder, ply_name.replace('.ply','_obst.ply')),   obstacle_pc)\n",
    "\n",
    "        # print(f\"{ply_name}: {len(flat_idx_global)} flat, {len(ramp_idx_global)} ramp, \"\n",
    "        #       f\"{len(non_ground_idx_list)} other obstacles\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eb3c746",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import open3d as o3d\n",
    "import CSF\n",
    "import os, re\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from collections import Counter\n",
    "\n",
    "for file_num in range(8):\n",
    "    file_num =  0 # <- You overwrite this, so the loop always uses 7\n",
    "    names = os.listdir(f'../data/{file_num}')\n",
    "    pattern_ply = re.compile(r'^[^\\.]+\\.ply$')\n",
    "    names_ply = [n for n in names if pattern_ply.match(n)]\n",
    "\n",
    "    for i in range(1, len(names_ply) + 1):\n",
    "        # Load point cloud\n",
    "        pcd = o3d.io.read_point_cloud(f'../data/{file_num}/{i}.ply')\n",
    "        xyz = np.asarray(pcd.points)\n",
    "        \n",
    "        # Load labels\n",
    "        label_path = f'../data/{file_num}/{i}_labels.npy'\n",
    "        labels = np.load(label_path).reshape(-1).astype(np.int32)\n",
    "\n",
    "        # --- Run CSF to classify ground vs obstacle ---\n",
    "        csf = CSF.CSF()\n",
    "        csf.params.bSloopSmooth = False\n",
    "        csf.params.cloth_resolution = 0.03\n",
    "        csf.params.rigidness = 1\n",
    "        csf.params.iterations = 500\n",
    "        csf.params.class_threshold = 0.1\n",
    "\n",
    "        csf.setPointCloud(xyz)\n",
    "        ground_idx = CSF.VecInt()\n",
    "        non_ground_idx = CSF.VecInt()\n",
    "        csf.do_filtering(ground_idx, non_ground_idx)\n",
    "\n",
    "        # Convert CSF indices to numpy arrays\n",
    "        ground_idx = np.array(list(ground_idx), dtype=int)\n",
    "        obstacle_idx = np.array(list(non_ground_idx), dtype=int)\n",
    "\n",
    "        # Assign ground/obstacle labels (1 = safe, 2 = unsafe)\n",
    "        csf_labels = np.zeros_like(labels)\n",
    "        csf_labels[ground_idx] = 1\n",
    "        csf_labels[obstacle_idx] = 2\n",
    "\n",
    "        # --- Apply KNN to propagate CSF labels to originally unlabeled points ---\n",
    "        k = 10\n",
    "        threshold = 0.7\n",
    "\n",
    "        labeled_idx = np.where(csf_labels != 0)[0]\n",
    "        unlabeled_idx = np.where(labels == 0)[0]\n",
    "\n",
    "        if labeled_idx.size > 0 and unlabeled_idx.size > 0:\n",
    "            knn = NearestNeighbors(n_neighbors=k).fit(xyz[labeled_idx])\n",
    "            distances, neighbor_indices = knn.kneighbors(xyz[unlabeled_idx])\n",
    "\n",
    "            for j, neighbors in enumerate(neighbor_indices):\n",
    "                neighbor_labels = csf_labels[labeled_idx[neighbors]]\n",
    "                most_common, count = Counter(neighbor_labels).most_common(1)[0]\n",
    "                if count / k >= threshold:\n",
    "                    labels[unlabeled_idx[j]] = most_common\n",
    "\n",
    "        # Save updated labels\n",
    "        np.save(label_path, labels)\n",
    "\n",
    "        # --- Visualization ---\n",
    "        label_to_color = {\n",
    "            0: (0.5, 0.5, 0.5),  # unlabeled\n",
    "            1: (0.0, 1.0, 0.0),  # safe\n",
    "            2: (1.0, 0.0, 0.0),  # unsafe\n",
    "        }\n",
    "\n",
    "        colors = np.array([label_to_color.get(l, (0.5, 0.5, 0.5)) for l in labels])\n",
    "        pcd.colors = o3d.utility.Vector3dVector(colors)\n",
    "        o3d.visualization.draw_geometries([pcd], window_name=f\"File {file_num}, Frame {i}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3c23dfe",
   "metadata": {},
   "source": [
    "clothes labelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "957716da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:36<00:00, 36.07s/it]\n"
     ]
    }
   ],
   "source": [
    "import open3d as o3d\n",
    "import numpy as np\n",
    "import os, re, cv2\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from collections import Counter\n",
    "import CSF\n",
    "from tqdm import tqdm\n",
    "output_frame_dir = \"rendered_frames\"\n",
    "os.makedirs(output_frame_dir, exist_ok=True)\n",
    "\n",
    "\n",
    "\n",
    "for file_num in tqdm(range(1,2)):  # Just 0 for now\n",
    "    file_output_dir = os.path.join(output_frame_dir, str(file_num))\n",
    "    os.makedirs(file_output_dir, exist_ok=True)\n",
    "    names = os.listdir(f'../data/{file_num}')\n",
    "    pattern_ply = re.compile(r'^[^\\.]+\\.ply$')\n",
    "    names_ply = sorted([n for n in names if pattern_ply.match(n)], key=lambda x: int(x.split('.')[0]))\n",
    "    frame_id = 0\n",
    "    for i in range(1, len(names_ply) + 1):\n",
    "        # Load point cloud\n",
    "        pcd = o3d.io.read_point_cloud(f'../data/{file_num}/{i}.ply')\n",
    "        xyz = np.asarray(pcd.points)\n",
    "\n",
    "        label_path = f'../data/{file_num}/{i}_labels.npy'\n",
    "        labels = np.load(label_path).reshape(-1).astype(np.int32)\n",
    "\n",
    "        # --- CSF ---\n",
    "        csf = CSF.CSF()\n",
    "        csf.params.bSloopSmooth = False\n",
    "        csf.params.cloth_resolution = 0.03\n",
    "        csf.params.rigidness = 1\n",
    "        csf.params.iterations = 500\n",
    "        csf.params.class_threshold = 0.1\n",
    "\n",
    "        csf.setPointCloud(xyz)\n",
    "        ground_idx = CSF.VecInt()\n",
    "        non_ground_idx = CSF.VecInt()\n",
    "        csf.do_filtering(ground_idx, non_ground_idx)\n",
    "\n",
    "        ground_idx = np.array(list(ground_idx), dtype=int)\n",
    "        obstacle_idx = np.array(list(non_ground_idx), dtype=int)\n",
    "\n",
    "        csf_labels = np.zeros_like(labels)\n",
    "        csf_labels[ground_idx] = 1\n",
    "        csf_labels[obstacle_idx] = 2\n",
    "\n",
    "        # --- KNN ---\n",
    "        k = 10\n",
    "        threshold = 0.7\n",
    "        labeled_idx = np.where(csf_labels != 0)[0]\n",
    "        unlabeled_idx = np.where(labels == 0)[0]\n",
    "\n",
    "        if labeled_idx.size > 0 and unlabeled_idx.size > 0:\n",
    "            knn = NearestNeighbors(n_neighbors=k).fit(xyz[labeled_idx])\n",
    "            _, neighbor_indices = knn.kneighbors(xyz[unlabeled_idx])\n",
    "            for j, neighbors in enumerate(neighbor_indices):\n",
    "                neighbor_labels = csf_labels[labeled_idx[neighbors]]\n",
    "                most_common, count = Counter(neighbor_labels).most_common(1)[0]\n",
    "                if count / k >= threshold:\n",
    "                    labels[unlabeled_idx[j]] = most_common\n",
    "\n",
    "        np.save(label_path, labels)\n",
    "\n",
    "        # # --- Assign colors and render to image ---\n",
    "        # label_to_color = {\n",
    "        #     0: (0.5, 0.5, 0.5),\n",
    "        #     1: (0.0, 1.0, 0.0),\n",
    "        #     2: (1.0, 0.0, 0.0),\n",
    "        # }\n",
    "        # colors = np.array([label_to_color.get(l, (0.5, 0.5, 0.5)) for l in labels])\n",
    "        # pcd.colors = o3d.utility.Vector3dVector(colors)\n",
    "\n",
    "        # vis = o3d.visualization.Visualizer()\n",
    "        # vis.create_window(visible=False)\n",
    "        # vis.add_geometry(pcd)\n",
    "        # vis.update_geometry(pcd)\n",
    "        # vis.poll_events()\n",
    "        # vis.update_renderer()\n",
    "        # vis.capture_screen_image(f\"{output_frame_dir}/{file_num}/frame_{frame_id:04d}.png\")\n",
    "        # vis.destroy_window()\n",
    "        # frame_id += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbe988ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "\n",
    "frame_dir = 'rendered_frames'\n",
    "file_num = 1\n",
    "frame_path = os.path.join(frame_dir, str(file_num))\n",
    "frame_files = sorted([f for f in os.listdir(frame_path) if f.endswith('.png')])\n",
    "\n",
    "if not frame_files:\n",
    "    raise ValueError(\"No frames found to create the video.\")\n",
    "\n",
    "# Read first image to determine size\n",
    "first_frame = cv2.imread(os.path.join(frame_path, frame_files[0]))\n",
    "height, width, _ = first_frame.shape\n",
    "out = cv2.VideoWriter('output_1.mp4', cv2.VideoWriter_fourcc(*'mp4v'), 5, (width, height))\n",
    "\n",
    "# Write all frames to video\n",
    "for frame_file in frame_files:\n",
    "    img = cv2.imread(os.path.join(frame_path, frame_file))\n",
    "    if img is not None:\n",
    "        out.write(img)\n",
    "\n",
    "out.release()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3913b7a8",
   "metadata": {},
   "source": [
    "# Label points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9042ad31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting cloth-simulation-filter\n",
      "  Downloading cloth_simulation_filter-1.1.5-cp312-cp312-win_amd64.whl.metadata (4.8 kB)\n",
      "Downloading cloth_simulation_filter-1.1.5-cp312-cp312-win_amd64.whl (132 kB)\n",
      "Installing collected packages: cloth-simulation-filter\n",
      "Successfully installed cloth-simulation-filter-1.1.5\n"
     ]
    }
   ],
   "source": [
    "!pip install cloth-simulation-filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cca7f89b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Frames in track 0: 100%|██████████| 31/31 [00:11<00:00,  2.65it/s]\n",
      "Frames in track 1: 100%|██████████| 146/146 [01:03<00:00,  2.28it/s]\n",
      "Frames in track 2: 100%|██████████| 1364/1364 [17:12<00:00,  1.32it/s]\n",
      "Frames in track 3: 100%|██████████| 437/437 [03:27<00:00,  2.10it/s]\n",
      "Frames in track 4: 100%|██████████| 292/292 [02:06<00:00,  2.30it/s]\n",
      "Frames in track 5: 100%|██████████| 45/45 [00:18<00:00,  2.37it/s]\n",
      "Frames in track 6:  49%|████▉     | 573/1171 [06:00<06:16,  1.59it/s]\n",
      "Tracks:  75%|███████▌  | 6/8 [30:22<10:07, 303.74s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-20eb18bccc3d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    122\u001b[0m         \u001b[0mcsf_labels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    123\u001b[0m         \u001b[0mcsf_labels\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mground_idx\u001b[0m\u001b[1;33m]\u001b[0m  \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 124\u001b[1;33m         \u001b[0mcsf_labels\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mobstacle_idx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    125\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    126\u001b[0m         \u001b[1;31m# --- KNN propagation to fill in any 0s ---\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "import open3d as o3d\n",
    "import numpy as np\n",
    "import CSF\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from collections import Counter\n",
    "\n",
    "def quat2rot(q):\n",
    "    qw, qx, qy, qz = q['w_val'], q['x_val'], q['y_val'], q['z_val']\n",
    "    return np.array([\n",
    "        [1-2*qy*qy-2*qz*qz,   2*qx*qy-2*qz*qw,     2*qx*qz+2*qy*qw],\n",
    "        [2*qx*qy+2*qz*qw,     1-2*qx*qx-2*qz*qz,   2*qy*qz-2*qx*qw],\n",
    "        [2*qx*qz-2*qy*qw,     2*qy*qz+2*qx*qw,     1-2*qx*qx-2*qy*qy]\n",
    "    ])\n",
    "\n",
    "def get_pose(state):\n",
    "    p = state['kinematics_estimated']['position']\n",
    "    o = state['kinematics_estimated']['orientation']\n",
    "    pos = np.array([p['x_val'], p['y_val'], p['z_val']], dtype=float)\n",
    "    return pos, quat2rot(o)\n",
    "\n",
    "def compute_labels_for_frame(track_path, frame_idx, threshold=1.2):\n",
    "    \"\"\"\n",
    "    Compute the 0/1/2 labels for frame `frame_idx` in folder `track_path`\n",
    "    using the same proximity + collision logic from your first script.\n",
    "    \"\"\"\n",
    "    plyf   = os.path.join(track_path, f\"{frame_idx}.ply\")\n",
    "    car0f  = os.path.join(track_path, f\"{frame_idx}_car_state.json\")\n",
    "    coll0f = os.path.join(track_path, f\"{frame_idx}_collision_info.json\")\n",
    "\n",
    "    if not (os.path.exists(plyf) and os.path.exists(car0f) and os.path.exists(coll0f)):\n",
    "        raise FileNotFoundError(f\"Missing base files for frame {frame_idx} in {track_path}\")\n",
    "\n",
    "    # load point cloud & initial car pose\n",
    "    cloud = o3d.io.read_point_cloud(plyf)\n",
    "    pts   = np.asarray(cloud.points)\n",
    "    car0  = json.load(open(car0f))\n",
    "    pos0, R0 = get_pose(car0)\n",
    "    world_pts = (R0 @ pts.T).T + pos0\n",
    "\n",
    "    ever_close     = np.zeros(len(world_pts), dtype=bool)\n",
    "    ever_collision = np.zeros(len(world_pts), dtype=bool)\n",
    "\n",
    "    # look at all future frames j = 1,2,3,...\n",
    "    j = 1\n",
    "    while True:\n",
    "        carjf  = os.path.join(track_path, f\"{j}_car_state.json\")\n",
    "        colljf = os.path.join(track_path, f\"{j}_collision_info.json\")\n",
    "        if not (os.path.exists(carjf) and os.path.exists(colljf)):\n",
    "            break\n",
    "\n",
    "        carj  = json.load(open(carjf))\n",
    "        collj = json.load(open(colljf))\n",
    "\n",
    "        # proximity\n",
    "        posj, _ = get_pose(carj)\n",
    "        d_car = np.linalg.norm(world_pts - posj, axis=1)\n",
    "        ever_close |= (d_car < (threshold - 0.2))\n",
    "\n",
    "        # collision\n",
    "        if collj['has_collided']:\n",
    "            cp = collj['position']\n",
    "            pos_col = np.array([cp['x_val'], cp['y_val'], cp['z_val']], dtype=float)\n",
    "            d_col = np.linalg.norm(world_pts - pos_col, axis=1)\n",
    "            ever_collision |= (d_col < (threshold + 0.2))\n",
    "\n",
    "        j += 1\n",
    "\n",
    "    # final labels: 0=uncertain, 1=safe, 2=risk\n",
    "    labels = np.zeros(len(world_pts), dtype=np.uint8)\n",
    "    labels[ ever_close & ~ever_collision ] = 1\n",
    "    labels[ ever_collision ] = 2\n",
    "\n",
    "    return labels\n",
    "\n",
    "# ——————— main processing loop ———————\n",
    "output_frame_dir = \"rendered_frames\"\n",
    "os.makedirs(output_frame_dir, exist_ok=True)\n",
    "\n",
    "data_root = \"../data\"\n",
    "threshold_check = 1.2   # or whatever you prefer\n",
    "k = 10                  # for KNN\n",
    "knn_thresh = 0.7        # for label propagation\n",
    "\n",
    "for file_num in tqdm(range(0, 8), desc=\"Tracks\"):  # change upper bound as needed\n",
    "    track_folder = os.path.join(data_root, str(file_num))\n",
    "    names = os.listdir(track_folder)\n",
    "    ply_files = sorted(\n",
    "        [n for n in names if re.match(r\"^\\d+\\.ply$\", n)],\n",
    "        key=lambda x: int(x.split(\".\")[0])\n",
    "    )\n",
    "\n",
    "    for ply_name in tqdm(ply_files, desc=f\"Frames in track {file_num}\"):\n",
    "        idx = int(ply_name.split(\".\")[0])\n",
    "        # load point cloud\n",
    "        pcd = o3d.io.read_point_cloud(os.path.join(track_folder, ply_name))\n",
    "        xyz = np.asarray(pcd.points)\n",
    "\n",
    "        # --- compute labels on the fly instead of np.load(...) ---\n",
    "        labels = compute_labels_for_frame(track_folder, idx, threshold=threshold_check)\n",
    "\n",
    "        # --- CSF ground/obstacle split ---\n",
    "        csf = CSF.CSF()\n",
    "        csf.params.bSloopSmooth = False\n",
    "        csf.params.cloth_resolution = 0.03\n",
    "        csf.params.rigidness = 1\n",
    "        csf.params.iterations = 500\n",
    "        csf.params.class_threshold = 0.1\n",
    "\n",
    "        csf.setPointCloud(xyz)\n",
    "        ground_idx = CSF.VecInt()\n",
    "        non_ground_idx = CSF.VecInt()\n",
    "        csf.do_filtering(ground_idx, non_ground_idx)\n",
    "\n",
    "        ground_idx = np.array(list(ground_idx), dtype=int)\n",
    "        obstacle_idx = np.array(list(non_ground_idx), dtype=int)\n",
    "\n",
    "        csf_labels = np.zeros_like(labels, dtype=np.int32)\n",
    "        csf_labels[ground_idx]  = 1\n",
    "        csf_labels[obstacle_idx] = 2\n",
    "\n",
    "        # --- KNN propagation to fill in any 0s ---\n",
    "        labeled_idx   = np.where(csf_labels != 0)[0]\n",
    "        unlabeled_idx = np.where(labels == 0)[0]\n",
    "\n",
    "        if labeled_idx.size and unlabeled_idx.size:\n",
    "            knn = NearestNeighbors(n_neighbors=k).fit(xyz[labeled_idx])\n",
    "            _, nbrs = knn.kneighbors(xyz[unlabeled_idx])\n",
    "            for j, neigh in enumerate(nbrs):\n",
    "                most_common, cnt = Counter(csf_labels[labeled_idx[neigh]]).most_common(1)[0]\n",
    "                if cnt / k >= knn_thresh:\n",
    "                    labels[unlabeled_idx[j]] = most_common\n",
    "\n",
    "        out_npy = os.path.join(track_folder, f\"{idx}_labels.npy\")\n",
    "        # print(out_npy)\n",
    "        np.save(out_npy, labels)\n",
    "\n",
    "\n",
    "        # colors = np.zeros_like(xyz)\n",
    "        # colors[labels == 0] = [0.5, 0.5, 0.5]  # gray\n",
    "        # colors[labels == 1] = [0.0, 1.0, 0.0]  # green\n",
    "        # colors[labels == 2] = [1.0, 0.0, 0.0]  # red\n",
    "        # pcd.colors = o3d.utility.Vector3dVector(colors)\n",
    "\n",
    "        # o3d.visualization.draw_geometries(\n",
    "        #     [pcd],\n",
    "        #     window_name=f\"Track {file_num} – Frame {idx}\",\n",
    "        #     width=800, height=600\n",
    "        # )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be91fd2c",
   "metadata": {},
   "source": [
    "### Visualize and captyure as IMage\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c96a679",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Frame in track 0: 100%|██████████| 31/31 [00:00<00:00, 38.19it/s]\n",
      "Frame in track 1: 100%|██████████| 146/146 [00:03<00:00, 39.87it/s]\n",
      "Tracks:  25%|██▌       | 2/8 [00:04<00:15,  2.58s/it]\n",
      "Frame in track 2:  66%|██████▌   | 901/1364 [00:22<00:11, 39.53it/s]\n",
      "Tracks:  25%|██▌       | 2/8 [00:27<01:22, 13.75s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 68\u001b[39m\n\u001b[32m     64\u001b[39m vis.create_window(width=\u001b[32m1280\u001b[39m, height=\u001b[32m720\u001b[39m, visible=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m     66\u001b[39m ctr = vis.get_view_control()\n\u001b[32m---> \u001b[39m\u001b[32m68\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m ply_name \u001b[38;5;129;01min\u001b[39;00m tqdm(ply_files, desc=\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFrame in track \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile_num\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m):\n\u001b[32m     69\u001b[39m     idx = ply_name[:-\u001b[32m4\u001b[39m]\n\u001b[32m     71\u001b[39m     \u001b[38;5;66;03m# --- load\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\gavin\\.conda\\envs\\visual\\Lib\\site-packages\\tqdm\\std.py:1191\u001b[39m, in \u001b[36mtqdm.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1189\u001b[39m dt = cur_t - last_print_t\n\u001b[32m   1190\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m dt >= mininterval \u001b[38;5;129;01mand\u001b[39;00m cur_t >= min_start_t:\n\u001b[32m-> \u001b[39m\u001b[32m1191\u001b[39m     \u001b[38;5;28mself\u001b[39m.update(n - last_print_n)\n\u001b[32m   1192\u001b[39m     last_print_n = \u001b[38;5;28mself\u001b[39m.last_print_n\n\u001b[32m   1193\u001b[39m     last_print_t = \u001b[38;5;28mself\u001b[39m.last_print_t\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\gavin\\.conda\\envs\\visual\\Lib\\site-packages\\tqdm\\std.py:1242\u001b[39m, in \u001b[36mtqdm.update\u001b[39m\u001b[34m(self, n)\u001b[39m\n\u001b[32m   1240\u001b[39m     \u001b[38;5;28mself\u001b[39m._ema_dn(dn)\n\u001b[32m   1241\u001b[39m     \u001b[38;5;28mself\u001b[39m._ema_dt(dt)\n\u001b[32m-> \u001b[39m\u001b[32m1242\u001b[39m \u001b[38;5;28mself\u001b[39m.refresh(lock_args=\u001b[38;5;28mself\u001b[39m.lock_args)\n\u001b[32m   1243\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.dynamic_miniters:\n\u001b[32m   1244\u001b[39m     \u001b[38;5;66;03m# If no `miniters` was specified, adjust automatically to the\u001b[39;00m\n\u001b[32m   1245\u001b[39m     \u001b[38;5;66;03m# maximum iteration rate seen so far between two prints.\u001b[39;00m\n\u001b[32m   1246\u001b[39m     \u001b[38;5;66;03m# e.g.: After running `tqdm.update(5)`, subsequent\u001b[39;00m\n\u001b[32m   1247\u001b[39m     \u001b[38;5;66;03m# calls to `tqdm.update()` will only cause an update after\u001b[39;00m\n\u001b[32m   1248\u001b[39m     \u001b[38;5;66;03m# at least 5 more iterations.\u001b[39;00m\n\u001b[32m   1249\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.maxinterval \u001b[38;5;129;01mand\u001b[39;00m dt >= \u001b[38;5;28mself\u001b[39m.maxinterval:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\gavin\\.conda\\envs\\visual\\Lib\\site-packages\\tqdm\\std.py:1347\u001b[39m, in \u001b[36mtqdm.refresh\u001b[39m\u001b[34m(self, nolock, lock_args)\u001b[39m\n\u001b[32m   1345\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1346\u001b[39m         \u001b[38;5;28mself\u001b[39m._lock.acquire()\n\u001b[32m-> \u001b[39m\u001b[32m1347\u001b[39m \u001b[38;5;28mself\u001b[39m.display()\n\u001b[32m   1348\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m nolock:\n\u001b[32m   1349\u001b[39m     \u001b[38;5;28mself\u001b[39m._lock.release()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\gavin\\.conda\\envs\\visual\\Lib\\site-packages\\tqdm\\std.py:1494\u001b[39m, in \u001b[36mtqdm.display\u001b[39m\u001b[34m(self, msg, pos)\u001b[39m\n\u001b[32m   1488\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m TqdmDeprecationWarning(\n\u001b[32m   1489\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mPlease use `tqdm.gui.tqdm(...)`\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1490\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m instead of `tqdm(..., gui=True)`\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   1491\u001b[39m         fp_write=\u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m.fp, \u001b[33m'\u001b[39m\u001b[33mwrite\u001b[39m\u001b[33m'\u001b[39m, sys.stderr.write))\n\u001b[32m   1493\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m pos:\n\u001b[32m-> \u001b[39m\u001b[32m1494\u001b[39m     \u001b[38;5;28mself\u001b[39m.moveto(pos)\n\u001b[32m   1495\u001b[39m \u001b[38;5;28mself\u001b[39m.sp(\u001b[38;5;28mself\u001b[39m.\u001b[34m__str__\u001b[39m() \u001b[38;5;28;01mif\u001b[39;00m msg \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m msg)\n\u001b[32m   1496\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m pos:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\gavin\\.conda\\envs\\visual\\Lib\\site-packages\\tqdm\\std.py:1443\u001b[39m, in \u001b[36mtqdm.moveto\u001b[39m\u001b[34m(self, n)\u001b[39m\n\u001b[32m   1441\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mmoveto\u001b[39m(\u001b[38;5;28mself\u001b[39m, n):\n\u001b[32m   1442\u001b[39m     \u001b[38;5;66;03m# TODO: private method\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1443\u001b[39m     \u001b[38;5;28mself\u001b[39m.fp.write(\u001b[33m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m'\u001b[39m * n + _term_move_up() * -n)\n\u001b[32m   1444\u001b[39m     \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m.fp, \u001b[33m'\u001b[39m\u001b[33mflush\u001b[39m\u001b[33m'\u001b[39m, \u001b[38;5;28;01mlambda\u001b[39;00m: \u001b[38;5;28;01mNone\u001b[39;00m)()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\gavin\\.conda\\envs\\visual\\Lib\\site-packages\\tqdm\\utils.py:196\u001b[39m, in \u001b[36mDisableOnWriteError.disable_on_exception.<locals>.inner\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    194\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minner\u001b[39m(*args, **kwargs):\n\u001b[32m    195\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m196\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m func(*args, **kwargs)\n\u001b[32m    197\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    198\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m e.errno != \u001b[32m5\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\gavin\\.conda\\envs\\visual\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:3027\u001b[39m, in \u001b[36mInteractiveShell._tee.<locals>.write\u001b[39m\u001b[34m(data, *args, **kwargs)\u001b[39m\n\u001b[32m   3025\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrite\u001b[39m(data, *args, **kwargs):\n\u001b[32m   3026\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Write data to both the original destination and the capture dictionary.\"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m3027\u001b[39m     result = original_write(data, *args, **kwargs)\n\u001b[32m   3028\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(\n\u001b[32m   3029\u001b[39m         [\n\u001b[32m   3030\u001b[39m             \u001b[38;5;28mself\u001b[39m.display_pub.is_publishing,\n\u001b[32m   (...)\u001b[39m\u001b[32m   3033\u001b[39m         ]\n\u001b[32m   3034\u001b[39m     ):\n\u001b[32m   3035\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\gavin\\.conda\\envs\\visual\\Lib\\site-packages\\ipykernel\\iostream.py:694\u001b[39m, in \u001b[36mOutStream.write\u001b[39m\u001b[34m(self, string)\u001b[39m\n\u001b[32m    692\u001b[39m     \u001b[38;5;28mself\u001b[39m.pub_thread.schedule(\u001b[38;5;28mself\u001b[39m._flush)\n\u001b[32m    693\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m694\u001b[39m     \u001b[38;5;28mself\u001b[39m._schedule_flush()\n\u001b[32m    696\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(string)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\gavin\\.conda\\envs\\visual\\Lib\\site-packages\\ipykernel\\iostream.py:590\u001b[39m, in \u001b[36mOutStream._schedule_flush\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    587\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_schedule_in_thread\u001b[39m():\n\u001b[32m    588\u001b[39m     \u001b[38;5;28mself\u001b[39m._io_loop.call_later(\u001b[38;5;28mself\u001b[39m.flush_interval, \u001b[38;5;28mself\u001b[39m._flush)\n\u001b[32m--> \u001b[39m\u001b[32m590\u001b[39m \u001b[38;5;28mself\u001b[39m.pub_thread.schedule(_schedule_in_thread)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\gavin\\.conda\\envs\\visual\\Lib\\site-packages\\ipykernel\\iostream.py:267\u001b[39m, in \u001b[36mIOPubThread.schedule\u001b[39m\u001b[34m(self, f)\u001b[39m\n\u001b[32m    265\u001b[39m     \u001b[38;5;28mself\u001b[39m._events.append(f)\n\u001b[32m    266\u001b[39m     \u001b[38;5;66;03m# wake event thread (message content is ignored)\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m267\u001b[39m     \u001b[38;5;28mself\u001b[39m._event_pipe.send(\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    268\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    269\u001b[39m     f()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\gavin\\.conda\\envs\\visual\\Lib\\site-packages\\zmq\\sugar\\socket.py:701\u001b[39m, in \u001b[36mSocket.send\u001b[39m\u001b[34m(self, data, flags, copy, track, routing_id, group)\u001b[39m\n\u001b[32m    694\u001b[39m         data = zmq.Frame(\n\u001b[32m    695\u001b[39m             data,\n\u001b[32m    696\u001b[39m             track=track,\n\u001b[32m    697\u001b[39m             copy=copy \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    698\u001b[39m             copy_threshold=\u001b[38;5;28mself\u001b[39m.copy_threshold,\n\u001b[32m    699\u001b[39m         )\n\u001b[32m    700\u001b[39m     data.group = group\n\u001b[32m--> \u001b[39m\u001b[32m701\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m().send(data, flags=flags, copy=copy, track=track)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m_zmq.py:1092\u001b[39m, in \u001b[36mzmq.backend.cython._zmq.Socket.send\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m_zmq.py:1140\u001b[39m, in \u001b[36mzmq.backend.cython._zmq.Socket.send\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m_zmq.py:1339\u001b[39m, in \u001b[36mzmq.backend.cython._zmq._send_copy\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m_zmq.py:160\u001b[39m, in \u001b[36mzmq.backend.cython._zmq._check_rc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import open3d as o3d\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "from scipy.spatial.transform import Rotation as R\n",
    "def quat2rot(q):\n",
    "    qw, qx, qy, qz = q['w_val'], q['x_val'], q['y_val'], q['z_val']\n",
    "    return np.array([\n",
    "        [1 - 2*qy**2 - 2*qz**2,   2*qx*qy - 2*qz*qw,     2*qx*qz + 2*qy*qw],\n",
    "        [2*qx*qy + 2*qz*qw,       1 - 2*qx**2 - 2*qz**2, 2*qy*qz - 2*qx*qw],\n",
    "        [2*qx*qz - 2*qy*qw,       2*qy*qz + 2*qx*qw,     1 - 2*qx**2 - 2*qy**2]\n",
    "    ])\n",
    "\n",
    "def get_pose(state):\n",
    "    p = state['kinematics_estimated']['position']\n",
    "    o = state['kinematics_estimated']['orientation']\n",
    "    pos = np.array([p['x_val'], p['y_val'], p['z_val']], dtype=float)\n",
    "    rot = quat2rot(o)\n",
    "    return pos, rot\n",
    "\n",
    "label_to_color = {\n",
    "    0: (0.5, 0.5, 0.5),\n",
    "    1: (0.0, 1.0, 0.0),\n",
    "    2: (1.0, 0.0, 0.0),\n",
    "}\n",
    "\n",
    "output_frame_dir = \"rendered_frames\"\n",
    "os.makedirs(output_frame_dir, exist_ok=True)\n",
    "\n",
    "# --- build car mesh ---\n",
    "car_mesh = o3d.geometry.TriangleMesh.create_box(width=0.8, height=0.4, depth=0.3)\n",
    "car_mesh.compute_vertex_normals()\n",
    "car_mesh.paint_uniform_color([0.0, 0.0, 0.0])        # red car\n",
    "center = car_mesh.get_center()\n",
    "car_mesh.translate(-center)\n",
    "\n",
    "# --- build a front arrow ---\n",
    "arrow = o3d.geometry.TriangleMesh.create_arrow(\n",
    "    cylinder_radius=0.03,    # shaft thickness\n",
    "    cone_radius=0.06,        # tip thickness\n",
    "    cylinder_height=0.2,     # shaft length\n",
    "    cone_height=0.1          # tip length\n",
    ")\n",
    "arrow.compute_vertex_normals()\n",
    "arrow.paint_uniform_color([1.0, 0.0, 0.0])   # make it bright red\n",
    "\n",
    "# default arrow points along +Z, so rotate it to point along +X\n",
    "\n",
    "R_y_neg90 = R.from_euler('y', -np.pi/2).as_matrix()\n",
    "arrow.rotate(R_y_neg90, center=(0,0,0))\n",
    "arrow.translate([0.2, 0, 0.5])\n",
    "\n",
    "for file_num in tqdm(range(8), desc=\"Tracks\"):\n",
    "    file_output_dir = os.path.join(output_frame_dir, str(file_num))\n",
    "    os.makedirs(file_output_dir, exist_ok=True)\n",
    "\n",
    "    data_dir = f'../data/{file_num}'\n",
    "    ply_files = sorted([f for f in os.listdir(data_dir) if f.endswith('.ply')],\n",
    "                       key=lambda x: int(x[:-4]))\n",
    "\n",
    "    # one window per track\n",
    "    vis = o3d.visualization.Visualizer()\n",
    "    vis.create_window(width=1280, height=720, visible=False)\n",
    "\n",
    "    ctr = vis.get_view_control()\n",
    "    \n",
    "    for ply_name in tqdm(ply_files, desc=f\"Frame in track {file_num}\"):\n",
    "        idx = ply_name[:-4]\n",
    "\n",
    "        # --- load\n",
    "        pcd = o3d.io.read_point_cloud(os.path.join(data_dir, ply_name))\n",
    "        labels = np.load(os.path.join(data_dir, f\"{idx}_labels.npy\")).astype(int).reshape(-1)\n",
    "        with open(os.path.join(data_dir, f\"{idx}_car_state.json\")) as f:\n",
    "            car_state = json.load(f)\n",
    "\n",
    "        # --- colorize\n",
    "        cols = np.array([label_to_color.get(l, label_to_color[0]) for l in labels])\n",
    "        pcd.colors = o3d.utility.Vector3dVector(cols)\n",
    "        mirror_x = np.eye(4)\n",
    "        mirror_x[0, 0] = -1.0\n",
    "        pcd.transform(mirror_x)\n",
    "\n",
    "        # --- get pose & flatten to yaw only\n",
    "        pos, rot_full = get_pose(car_state)\n",
    "        pos[0] *= -1  # mirror X\n",
    "        rot_full = np.diag([-1, 1, 1]) @ rot_full  # mirror orientation\n",
    "\n",
    "        yaw = np.arctan2(rot_full[1, 0], rot_full[0, 0])\n",
    "        rot_flat = R.from_euler('z', yaw, degrees=False).as_matrix()\n",
    "\n",
    "        # --- chase‐cam in flattened frame\n",
    "        offset_local = np.array([-7, 0, -5.0])\n",
    "        lookat = car_mesh.get_center() + np.array([0.0, 0.0, 0.95])\n",
    "        cam_pos = car_mesh.get_center() + ( offset_local)\n",
    "\n",
    "        # --- render\n",
    "        vis.clear_geometries()\n",
    "        vis.add_geometry(pcd)\n",
    "        vis.add_geometry(car_mesh)  \n",
    "        vis.add_geometry(arrow)\n",
    "        ctr.set_lookat( lookat )\n",
    "        front = (lookat - cam_pos)\n",
    "        front /= np.linalg.norm(front)\n",
    "        ctr.set_front( front.tolist() )\n",
    "        ctr.set_up([0, 0, 1])\n",
    "        ctr.set_zoom(0.4)\n",
    "\n",
    "        vis.poll_events()\n",
    "        vis.update_renderer()\n",
    "        # vis.run()\n",
    "        # time.sleep(0.1)\n",
    "        img_path = os.path.join(file_output_dir, f\"{idx}.png\")\n",
    "        vis.capture_screen_image(img_path)\n",
    "\n",
    "    vis.destroy_window()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6241899d",
   "metadata": {},
   "source": [
    "Make video "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25767a24",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Making videos:  12%|█▎        | 1/8 [00:00<00:03,  1.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " → Saved video: videos\\track_0.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Making videos:  25%|██▌       | 2/8 [00:03<00:11,  1.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " → Saved video: videos\\track_1.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Making videos:  38%|███▊      | 3/8 [00:30<01:06, 13.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " → Saved video: videos\\track_2.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Making videos:  50%|█████     | 4/8 [00:39<00:46, 11.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " → Saved video: videos\\track_3.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Making videos:  62%|██████▎   | 5/8 [00:44<00:28,  9.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " → Saved video: videos\\track_4.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Making videos:  75%|███████▌  | 6/8 [00:45<00:13,  6.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " → Saved video: videos\\track_5.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Making videos:  88%|████████▊ | 7/8 [01:13<00:13, 13.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " → Saved video: videos\\track_6.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Making videos: 100%|██████████| 8/8 [01:47<00:00, 13.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " → Saved video: videos\\track_7.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "\n",
    "# folders\n",
    "frame_folder       = 'rendered_frames'   # where your point images live, in subfolders 0,1,...,7\n",
    "camera_pic_folder  = '../data'           # where your camera images live, same subfolder structure\n",
    "output_folder      = 'videos'            # where the .mp4 files will be written\n",
    "\n",
    "# make sure output_folder exists\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# parameters\n",
    "fps = 30  # frames per second for the output video\n",
    "\n",
    "def resize_to_height(img, target_h):\n",
    "    h, w = img.shape[:2]\n",
    "    scale = target_h / float(h)\n",
    "    return cv2.resize(img, (int(w * scale), target_h))\n",
    "\n",
    "for track_id in tqdm(range(8), desc=\"Making videos\"):\n",
    "    cam_dir   = os.path.join(camera_pic_folder,  str(track_id))\n",
    "    point_dir = os.path.join(frame_folder,       str(track_id))\n",
    "    \n",
    "    # collect and sort PNGs by numeric name (e.g. \"0.png\", \"1.png\", ...)\n",
    "    files = sorted(\n",
    "        [f for f in os.listdir(cam_dir) if f.lower().endswith('.png')],\n",
    "        key=lambda fn: int(os.path.splitext(fn)[0])\n",
    "    )\n",
    "    if not files:\n",
    "        print(f\" → no images in {cam_dir}, skipping\")\n",
    "        continue\n",
    "\n",
    "    # load first pair to determine output size\n",
    "    p0 = cv2.imread(os.path.join(point_dir, files[0]))\n",
    "    c0 = cv2.imread(os.path.join(cam_dir,   files[0]))\n",
    "    if p0 is None or c0 is None:\n",
    "        raise RuntimeError(f\"Could not read {files[0]} from one of the folders\")\n",
    "\n",
    "    # match heights\n",
    "    H = max(p0.shape[0], c0.shape[0])\n",
    "    p0 = resize_to_height(p0, H)\n",
    "    c0 = resize_to_height(c0, H)\n",
    "\n",
    "    # setup video writer\n",
    "    W = p0.shape[1] + c0.shape[1]\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    out_path = os.path.join(output_folder, f'track_{track_id}.mp4')\n",
    "    writer = cv2.VideoWriter(out_path, fourcc, fps, (W, H))\n",
    "    \n",
    "    # write first frame\n",
    "    writer.write(cv2.hconcat([p0, c0]))\n",
    "\n",
    "    # process remaining frames\n",
    "    for fname in files[1:]:\n",
    "        p = cv2.imread(os.path.join(point_dir, fname))\n",
    "        c = cv2.imread(os.path.join(cam_dir,   fname))\n",
    "        if p is None or c is None:\n",
    "            print(f\"  ✗ skipping {fname} (failed to load)\")\n",
    "            continue\n",
    "        p = resize_to_height(p, H)\n",
    "        c = resize_to_height(c, H)\n",
    "        writer.write(cv2.hconcat([p, c]))\n",
    "\n",
    "    writer.release()\n",
    "    print(f\" → Saved video: {out_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "point",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
