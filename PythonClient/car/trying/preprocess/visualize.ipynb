{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e021412d",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcluster\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m KMeans\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m  \u001b[39m\u001b[34;01mopen3d\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mo3d\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'sklearn'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "import  open3d as o3d\n",
    "import numpy as np\n",
    "import open3d as o3d\n",
    "import os\n",
    "import re\n",
    "file_num = 0\n",
    "\n",
    "# Example data (replace with actual point cloud and initial labels)\n",
    "# load points and labels\n",
    "label_to_color = {\n",
    "        0: (0.0, 0.0, 0.0),\n",
    "        1: (0.0, 1.0, 0.0),\n",
    "        2: (1.0, 0.0, 0.0),\n",
    "    }\n",
    "for file_num in range(8):\n",
    "    names = os.listdir(f'../data/{file_num}')\n",
    "    pattern_ply = re.compile(r'^[^\\.]+\\.ply$')\n",
    "    names_ply = [n for n in names if pattern_ply.match(n)]\n",
    "    for i in range(1, len(names_ply) + 1):\n",
    "        pc_path = f'../data/{file_num}/{i}.ply'  # replace with your point cloud file\n",
    "        label_path = f'../data/{file_num}/{i}_labels.npy'  # replace with your label file\n",
    "        pcd = o3d.io.read_point_cloud(pc_path)\n",
    "        points = np.asarray(pcd.points)        # shape (N, 3)\n",
    "        labels = np.load(label_path).reshape(-1).astype(np.int32)# 1 = safe, 0 = unsafe, -1 = unlabeled\n",
    "\n",
    "        # Apply K-Means clustering to all points\n",
    "        K = 25 # for example, 15 clusters (tune this as needed)\n",
    "        kmeans = KMeans(n_clusters=K, random_state=42)\n",
    "        cluster_ids = kmeans.fit_predict(points)\n",
    "\n",
    "        # Determine majority label in each cluster\n",
    "        cluster_label = {}  # map cluster_id -> assigned label\n",
    "        for cid in range(K):\n",
    "            idx = np.where(cluster_ids == cid)[0]               # indices of points in this cluster\n",
    "            labeled_idx = idx[labels[idx] != -1]                # indices of labeled points in cluster\n",
    "            if labeled_idx.size == 0:\n",
    "                continue  # no label info in this cluster; skip assigning\n",
    "            # Count safe vs unsafe among known labels in cluster\n",
    "            safe_count = np.sum(labels[labeled_idx] == 1)\n",
    "            unsafe_count = np.sum(labels[labeled_idx] == 2)\n",
    "            # Decide label if one class dominates\n",
    "            total_labeled = safe_count + unsafe_count\n",
    "            if total_labeled > 0:\n",
    "                majority_label = 1 if safe_count > unsafe_count else 2\n",
    "                frac = max(safe_count, unsafe_count) / total_labeled\n",
    "                # print(f\"Cluster {cid} - Safe: {safe_count}, Unsafe: {unsafe_count}, Fraction: {frac:.2f}\")\n",
    "                if frac >= 0.70:  # e.g., require at least 70% agreement\n",
    "                    cluster_label[cid] = majority_label\n",
    "        # Assign labels to unlabeled points based on cluster majority\n",
    "        new_labels = labels.copy()\n",
    "        for cid, lbl in cluster_label.items():\n",
    "            # print(f\"Cluster {cid} majority label: {lbl}\")\n",
    "            # print(f\"Cluster {cid} majority label: {lbl}\")\n",
    "            idx = np.where(cluster_ids == cid)[0]\n",
    "            # Label only those that were unlabeled\n",
    "            unl_idx = idx[new_labels[idx] == 0]\n",
    "        #     new_labels[unl_idx] = lbl\n",
    "        # # save the new labels\n",
    "        # print(\"Total number oif pints\", len(new_labels)-len(labels))\n",
    "        # print(f\"number of zero label before the point cloud: {np.sum(new_labels == 0)- np.sum(labels == 0)}\")\n",
    "        np.save(f'../data/{file_num}/{i}_labels.npy', new_labels)\n",
    "        print(\"done \", file_num)\n",
    "    # print(f\"number of zero label after the point cloud: {np.sum(new_labels == 0)}\")\n",
    "    # # 'new_labels' now contains expanded labels for points that met the criteria\n",
    "    # print(\"unique labels after clustering:\", np.unique(new_labels))\n",
    "    # # visualize the results\n",
    "    # pcd.colors = o3d.utility.Vector3dVector(np.array([label_to_color[l] for l in new_labels], dtype=np.float64))\n",
    "    # o3d.visualization.draw_geometries([pcd])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d44c2dc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import open3d as o3d\n",
    "import os\n",
    "import re\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from collections import Counter\n",
    "\n",
    "label_to_color = {\n",
    "    0: (0.0, 0.0, 0.0),\n",
    "    1: (0.0, 1.0, 0.0),\n",
    "    2: (1.0, 0.0, 0.0),\n",
    "}\n",
    "\n",
    "k = 50  # Number of neighbors\n",
    "threshold = 0.4  # 70% majority required to assign label\n",
    "\n",
    "for file_num in range(8):\n",
    "    names = os.listdir(f'../data/{file_num}')\n",
    "    pattern_ply = re.compile(r'^[^\\.]+\\.ply$')\n",
    "    names_ply = [n for n in names if pattern_ply.match(n)]\n",
    "    \n",
    "    for i in range(1, len(names_ply) + 1):\n",
    "        pc_path = f'../data/{file_num}/{i}.ply'\n",
    "        label_path = f'../data/{file_num}/{i}_labels.npy'\n",
    "        \n",
    "        pcd = o3d.io.read_point_cloud(pc_path)\n",
    "        points = np.asarray(pcd.points)\n",
    "        labels = np.load(label_path).reshape(-1).astype(np.int32)\n",
    "\n",
    "        labeled_idx = np.where((labels == 1) | (labels == 2))[0]\n",
    "        unlabeled_idx = np.where(labels == 0)[0]\n",
    "\n",
    "        if labeled_idx.size == 0 or unlabeled_idx.size == 0:\n",
    "            continue\n",
    "\n",
    "        labeled_points = points[labeled_idx]\n",
    "        unlabeled_points = points[unlabeled_idx]\n",
    "        labeled_labels = labels[labeled_idx]\n",
    "\n",
    "        nbrs = NearestNeighbors(n_neighbors=k, algorithm='auto').fit(labeled_points)\n",
    "        distances, indices = nbrs.kneighbors(unlabeled_points)\n",
    "\n",
    "        new_labels = labels.copy()\n",
    "\n",
    "        for j, neighbor_idxs in enumerate(indices):\n",
    "            neighbor_labels = labeled_labels[neighbor_idxs]\n",
    "            label_counts = Counter(neighbor_labels)\n",
    "            most_common_label, count = label_counts.most_common(1)[0]\n",
    "            if count / k >= threshold:\n",
    "                new_labels[unlabeled_idx[j]] = most_common_label\n",
    "\n",
    "        # np.save(f'../data/{file_num}/{i}_labels.npy', new_labels)\n",
    "        # print(\"Done:\", file_num, i)\n",
    "        # Map labels to colors (make sure the label_to_color dictionary is defined)\n",
    "        colors = np.array([label_to_color.get(lbl, (0.5, 0.5, 0.5)) for lbl in new_labels], dtype=np.float64)\n",
    "        pcd.colors = o3d.utility.Vector3dVector(colors)\n",
    "        o3d.visualization.draw_geometries([pcd], window_name=f\"Point Cloud {file_num}-{i}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b067ec7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-d6eeb72d1c4e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m         \u001b[1;31m# 5) Visualize\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 42\u001b[1;33m         \u001b[0mo3d\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvisualization\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdraw_geometries\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mground_pc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobstacle_pc\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import open3d as o3d\n",
    "import CSF\n",
    "import os, re\n",
    "# ---- your existing setup ----\n",
    "# file_num = 0\n",
    "# i = 5\n",
    "for file_num in range(8):\n",
    "    file_num =7\n",
    "    names = os.listdir(f'../data/{file_num}')\n",
    "    pattern_ply = re.compile(r'^[^\\.]+\\.ply$')\n",
    "    names_ply = [n for n in names if pattern_ply.match(n)]\n",
    "    for i in range(1, len(names_ply) + 1):\n",
    "        pcd = o3d.io.read_point_cloud(f'../data/{file_num}/{i}.ply')\n",
    "        xyz = np.asarray(pcd.points)\n",
    "\n",
    "        # 2) Configure the CSF filter\n",
    "        csf = CSF.CSF()\n",
    "        csf.params.bSloopSmooth    = False    # smooth out small terrain noise\n",
    "        csf.params.cloth_resolution = 0.03    # size of cloth mesh cells (m)\n",
    "        # (optional) tweak these too:\n",
    "        csf.params.rigidness    = 1\n",
    "        csf.params.iterations   = 500\n",
    "        csf.params.class_threshold = 0.1\n",
    "\n",
    "        # 3) Run the filter\n",
    "        csf.setPointCloud(xyz)\n",
    "        ground_idx     = CSF.VecInt()       # will hold indices of ground points\n",
    "        non_ground_idx = CSF.VecInt()       # will hold indices of obstacles\n",
    "        csf.do_filtering(ground_idx, non_ground_idx)\n",
    "\n",
    "        # 4) Extract and color\n",
    "        ground_pts   = xyz[np.array(list(ground_idx),     dtype=int)]\n",
    "        obstacle_pts = xyz[np.array(list(non_ground_idx), dtype=int)]\n",
    "        ground_pc     = o3d.geometry.PointCloud(o3d.utility.Vector3dVector(ground_pts))\n",
    "        obstacle_pc   = o3d.geometry.PointCloud(o3d.utility.Vector3dVector(obstacle_pts))\n",
    "\n",
    "        ground_pc.paint_uniform_color([0.0, 1.0, 0.0])   # gray = ground\n",
    "        obstacle_pc.paint_uniform_color([1.0, 0.0, 0.0]) # red  = obstacles\n",
    "\n",
    "        # 5) Visualize\n",
    "        o3d.visualization.draw_geometries([ground_pc, obstacle_pc])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5188a7c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-94f693d6496b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     69\u001b[0m             \u001b[0mwidth\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m800\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     70\u001b[0m             \u001b[0mheight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m600\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 71\u001b[1;33m             \u001b[0mmesh_show_back_face\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     72\u001b[0m         )\n\u001b[0;32m     73\u001b[0m         \u001b[1;31m# visua;oze\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import open3d as o3d\n",
    "import CSF\n",
    "\n",
    "BASE_DIR = '../data'\n",
    "SLOPE_THRESHOLD_DEG = 10.0   # ramp if normal deviates more than this from vertical\n",
    "\n",
    "for file_num in range(8):\n",
    "    file_num =7\n",
    "    folder = os.path.join(BASE_DIR, str(file_num))\n",
    "    if not os.path.isdir(folder):\n",
    "        continue\n",
    "\n",
    "    ply_files = sorted(f for f in os.listdir(folder) if f.lower().endswith('.ply'))\n",
    "    for ply_name in ply_files:\n",
    "        # 1) load\n",
    "        ply_path = os.path.join(folder, ply_name)\n",
    "        pcd = o3d.io.read_point_cloud(ply_path)\n",
    "        xyz = np.asarray(pcd.points)\n",
    "\n",
    "        # 2) estimate normals once on full cloud\n",
    "        pcd.estimate_normals(search_param=o3d.geometry.KDTreeSearchParamKNN(knn=30))\n",
    "        normals = np.asarray(pcd.normals)  # shape (N,3)\n",
    "\n",
    "        # 3) run CSF\n",
    "        csf = CSF.CSF()\n",
    "        csf.params.bSloopSmooth     = True\n",
    "        csf.params.cloth_resolution = 0.1\n",
    "        csf.params.rigidness        = 5\n",
    "        csf.params.iterations       = 500\n",
    "        csf.params.class_threshold  = 0.5\n",
    "\n",
    "        csf.setPointCloud(xyz)\n",
    "        ground_idx     = CSF.VecInt()\n",
    "        non_ground_idx = CSF.VecInt()\n",
    "        csf.do_filtering(ground_idx, non_ground_idx)\n",
    "\n",
    "        # convert to Python lists\n",
    "        ground_idx_list     = np.array(list(ground_idx), dtype=int)\n",
    "        non_ground_idx_list = np.array(list(non_ground_idx), dtype=int)\n",
    "\n",
    "        # 4) detect ramps in the ground set\n",
    "        g_normals = normals[ground_idx_list]                   # normals for CSF‐ground\n",
    "        # angle from vertical = arccos(|n·[0,0,1]|)\n",
    "        angles = np.degrees(np.arccos(np.clip(np.abs(g_normals[:,2]), -1.0, 1.0)))\n",
    "        ramp_mask = angles > SLOPE_THRESHOLD_DEG\n",
    "\n",
    "        ramp_idx_global = ground_idx_list[ramp_mask]           # these are the ramps\n",
    "        flat_idx_global = ground_idx_list[~ramp_mask]          # truly flat ground\n",
    "\n",
    "        # 5) assemble final indices\n",
    "        final_ground_idx   = flat_idx_global\n",
    "        final_obstacle_idx = np.concatenate([non_ground_idx_list, ramp_idx_global])\n",
    "\n",
    "        # 6) extract point clouds\n",
    "        ground_pc   = o3d.geometry.PointCloud(o3d.utility.Vector3dVector(xyz[final_ground_idx]))\n",
    "        obstacle_pc = o3d.geometry.PointCloud(o3d.utility.Vector3dVector(xyz[final_obstacle_idx]))\n",
    "\n",
    "        # color: green=flat ground, blue=ramps, red=other obstacles\n",
    "        ground_pc.paint_uniform_color([0.0, 1.0, 0.0])\n",
    "        # optionally visualize ramps separately:\n",
    "        ramp_pc = o3d.geometry.PointCloud(o3d.utility.Vector3dVector(xyz[ramp_idx_global]))\n",
    "        ramp_pc.paint_uniform_color([0.0, 0.0, 1.0])\n",
    "        obstacle_pc.paint_uniform_color([1.0, 0.0, 0.0])\n",
    "        o3d.visualization.draw_geometries(\n",
    "            [ground_pc, ramp_pc, obstacle_pc],\n",
    "            window_name=f\"Segmentation: {ply_name}\",\n",
    "            width=800,\n",
    "            height=600,\n",
    "            mesh_show_back_face=True\n",
    "        )\n",
    "        # visua;oze \n",
    "        # # 7) write or visualize\n",
    "        # o3d.io.write_point_cloud(os.path.join(folder, ply_name.replace('.ply','_flat.ply')),   ground_pc)\n",
    "        # o3d.io.write_point_cloud(os.path.join(folder, ply_name.replace('.ply','_ramp.ply')),   ramp_pc)\n",
    "        # o3d.io.write_point_cloud(os.path.join(folder, ply_name.replace('.ply','_obst.ply')),   obstacle_pc)\n",
    "\n",
    "        # print(f\"{ply_name}: {len(flat_idx_global)} flat, {len(ramp_idx_global)} ramp, \"\n",
    "        #       f\"{len(non_ground_idx_list)} other obstacles\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eb3c746",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import open3d as o3d\n",
    "import CSF\n",
    "import os, re\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from collections import Counter\n",
    "\n",
    "for file_num in range(8):\n",
    "    file_num =  0 # <- You overwrite this, so the loop always uses 7\n",
    "    names = os.listdir(f'../data/{file_num}')\n",
    "    pattern_ply = re.compile(r'^[^\\.]+\\.ply$')\n",
    "    names_ply = [n for n in names if pattern_ply.match(n)]\n",
    "\n",
    "    for i in range(1, len(names_ply) + 1):\n",
    "        # Load point cloud\n",
    "        pcd = o3d.io.read_point_cloud(f'../data/{file_num}/{i}.ply')\n",
    "        xyz = np.asarray(pcd.points)\n",
    "        \n",
    "        # Load labels\n",
    "        label_path = f'../data/{file_num}/{i}_labels.npy'\n",
    "        labels = np.load(label_path).reshape(-1).astype(np.int32)\n",
    "\n",
    "        # --- Run CSF to classify ground vs obstacle ---\n",
    "        csf = CSF.CSF()\n",
    "        csf.params.bSloopSmooth = False\n",
    "        csf.params.cloth_resolution = 0.03\n",
    "        csf.params.rigidness = 1\n",
    "        csf.params.iterations = 500\n",
    "        csf.params.class_threshold = 0.1\n",
    "\n",
    "        csf.setPointCloud(xyz)\n",
    "        ground_idx = CSF.VecInt()\n",
    "        non_ground_idx = CSF.VecInt()\n",
    "        csf.do_filtering(ground_idx, non_ground_idx)\n",
    "\n",
    "        # Convert CSF indices to numpy arrays\n",
    "        ground_idx = np.array(list(ground_idx), dtype=int)\n",
    "        obstacle_idx = np.array(list(non_ground_idx), dtype=int)\n",
    "\n",
    "        # Assign ground/obstacle labels (1 = safe, 2 = unsafe)\n",
    "        csf_labels = np.zeros_like(labels)\n",
    "        csf_labels[ground_idx] = 1\n",
    "        csf_labels[obstacle_idx] = 2\n",
    "\n",
    "        # --- Apply KNN to propagate CSF labels to originally unlabeled points ---\n",
    "        k = 10\n",
    "        threshold = 0.7\n",
    "\n",
    "        labeled_idx = np.where(csf_labels != 0)[0]\n",
    "        unlabeled_idx = np.where(labels == 0)[0]\n",
    "\n",
    "        if labeled_idx.size > 0 and unlabeled_idx.size > 0:\n",
    "            knn = NearestNeighbors(n_neighbors=k).fit(xyz[labeled_idx])\n",
    "            distances, neighbor_indices = knn.kneighbors(xyz[unlabeled_idx])\n",
    "\n",
    "            for j, neighbors in enumerate(neighbor_indices):\n",
    "                neighbor_labels = csf_labels[labeled_idx[neighbors]]\n",
    "                most_common, count = Counter(neighbor_labels).most_common(1)[0]\n",
    "                if count / k >= threshold:\n",
    "                    labels[unlabeled_idx[j]] = most_common\n",
    "\n",
    "        # Save updated labels\n",
    "        np.save(label_path, labels)\n",
    "\n",
    "        # --- Visualization ---\n",
    "        label_to_color = {\n",
    "            0: (0.5, 0.5, 0.5),  # unlabeled\n",
    "            1: (0.0, 1.0, 0.0),  # safe\n",
    "            2: (1.0, 0.0, 0.0),  # unsafe\n",
    "        }\n",
    "\n",
    "        colors = np.array([label_to_color.get(l, (0.5, 0.5, 0.5)) for l in labels])\n",
    "        pcd.colors = o3d.utility.Vector3dVector(colors)\n",
    "        o3d.visualization.draw_geometries([pcd], window_name=f\"File {file_num}, Frame {i}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3c23dfe",
   "metadata": {},
   "source": [
    "clothes labelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "957716da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:36<00:00, 36.07s/it]\n"
     ]
    }
   ],
   "source": [
    "import open3d as o3d\n",
    "import numpy as np\n",
    "import os, re, cv2\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from collections import Counter\n",
    "import CSF\n",
    "from tqdm import tqdm\n",
    "output_frame_dir = \"rendered_frames\"\n",
    "os.makedirs(output_frame_dir, exist_ok=True)\n",
    "\n",
    "\n",
    "\n",
    "for file_num in tqdm(range(1,2)):  # Just 0 for now\n",
    "    file_output_dir = os.path.join(output_frame_dir, str(file_num))\n",
    "    os.makedirs(file_output_dir, exist_ok=True)\n",
    "    names = os.listdir(f'../data/{file_num}')\n",
    "    pattern_ply = re.compile(r'^[^\\.]+\\.ply$')\n",
    "    names_ply = sorted([n for n in names if pattern_ply.match(n)], key=lambda x: int(x.split('.')[0]))\n",
    "    frame_id = 0\n",
    "    for i in range(1, len(names_ply) + 1):\n",
    "        # Load point cloud\n",
    "        pcd = o3d.io.read_point_cloud(f'../data/{file_num}/{i}.ply')\n",
    "        xyz = np.asarray(pcd.points)\n",
    "\n",
    "        label_path = f'../data/{file_num}/{i}_labels.npy'\n",
    "        labels = np.load(label_path).reshape(-1).astype(np.int32)\n",
    "\n",
    "        # --- CSF ---\n",
    "        csf = CSF.CSF()\n",
    "        csf.params.bSloopSmooth = False\n",
    "        csf.params.cloth_resolution = 0.03\n",
    "        csf.params.rigidness = 1\n",
    "        csf.params.iterations = 500\n",
    "        csf.params.class_threshold = 0.1\n",
    "\n",
    "        csf.setPointCloud(xyz)\n",
    "        ground_idx = CSF.VecInt()\n",
    "        non_ground_idx = CSF.VecInt()\n",
    "        csf.do_filtering(ground_idx, non_ground_idx)\n",
    "\n",
    "        ground_idx = np.array(list(ground_idx), dtype=int)\n",
    "        obstacle_idx = np.array(list(non_ground_idx), dtype=int)\n",
    "\n",
    "        csf_labels = np.zeros_like(labels)\n",
    "        csf_labels[ground_idx] = 1\n",
    "        csf_labels[obstacle_idx] = 2\n",
    "\n",
    "        # --- KNN ---\n",
    "        k = 10\n",
    "        threshold = 0.7\n",
    "        labeled_idx = np.where(csf_labels != 0)[0]\n",
    "        unlabeled_idx = np.where(labels == 0)[0]\n",
    "\n",
    "        if labeled_idx.size > 0 and unlabeled_idx.size > 0:\n",
    "            knn = NearestNeighbors(n_neighbors=k).fit(xyz[labeled_idx])\n",
    "            _, neighbor_indices = knn.kneighbors(xyz[unlabeled_idx])\n",
    "            for j, neighbors in enumerate(neighbor_indices):\n",
    "                neighbor_labels = csf_labels[labeled_idx[neighbors]]\n",
    "                most_common, count = Counter(neighbor_labels).most_common(1)[0]\n",
    "                if count / k >= threshold:\n",
    "                    labels[unlabeled_idx[j]] = most_common\n",
    "\n",
    "        np.save(label_path, labels)\n",
    "\n",
    "        # # --- Assign colors and render to image ---\n",
    "        # label_to_color = {\n",
    "        #     0: (0.5, 0.5, 0.5),\n",
    "        #     1: (0.0, 1.0, 0.0),\n",
    "        #     2: (1.0, 0.0, 0.0),\n",
    "        # }\n",
    "        # colors = np.array([label_to_color.get(l, (0.5, 0.5, 0.5)) for l in labels])\n",
    "        # pcd.colors = o3d.utility.Vector3dVector(colors)\n",
    "\n",
    "        # vis = o3d.visualization.Visualizer()\n",
    "        # vis.create_window(visible=False)\n",
    "        # vis.add_geometry(pcd)\n",
    "        # vis.update_geometry(pcd)\n",
    "        # vis.poll_events()\n",
    "        # vis.update_renderer()\n",
    "        # vis.capture_screen_image(f\"{output_frame_dir}/{file_num}/frame_{frame_id:04d}.png\")\n",
    "        # vis.destroy_window()\n",
    "        # frame_id += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbe988ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "\n",
    "frame_dir = 'rendered_frames'\n",
    "file_num = 1\n",
    "frame_path = os.path.join(frame_dir, str(file_num))\n",
    "frame_files = sorted([f for f in os.listdir(frame_path) if f.endswith('.png')])\n",
    "\n",
    "if not frame_files:\n",
    "    raise ValueError(\"No frames found to create the video.\")\n",
    "\n",
    "# Read first image to determine size\n",
    "first_frame = cv2.imread(os.path.join(frame_path, frame_files[0]))\n",
    "height, width, _ = first_frame.shape\n",
    "out = cv2.VideoWriter('output_1.mp4', cv2.VideoWriter_fourcc(*'mp4v'), 5, (width, height))\n",
    "\n",
    "# Write all frames to video\n",
    "for frame_file in frame_files:\n",
    "    img = cv2.imread(os.path.join(frame_path, frame_file))\n",
    "    if img is not None:\n",
    "        out.write(img)\n",
    "\n",
    "out.release()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3913b7a8",
   "metadata": {},
   "source": [
    "# Label points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cca7f89b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tracks:   0%|          | 0/8 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "import open3d as o3d\n",
    "import numpy as np\n",
    "import CSF\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from collections import Counter\n",
    "\n",
    "def quat2rot(q):\n",
    "    qw, qx, qy, qz = q['w_val'], q['x_val'], q['y_val'], q['z_val']\n",
    "    return np.array([\n",
    "        [1-2*qy*qy-2*qz*qz,   2*qx*qy-2*qz*qw,     2*qx*qz+2*qy*qw],\n",
    "        [2*qx*qy+2*qz*qw,     1-2*qx*qx-2*qz*qz,   2*qy*qz-2*qx*qw],\n",
    "        [2*qx*qz-2*qy*qw,     2*qy*qz+2*qx*qw,     1-2*qx*qx-2*qy*qy]\n",
    "    ])\n",
    "\n",
    "def get_pose(state):\n",
    "    p = state['kinematics_estimated']['position']\n",
    "    o = state['kinematics_estimated']['orientation']\n",
    "    pos = np.array([p['x_val'], p['y_val'], p['z_val']], dtype=float)\n",
    "    return pos, quat2rot(o)\n",
    "\n",
    "def compute_labels_for_frame(track_path, frame_idx, threshold=1.2):\n",
    "    \"\"\"\n",
    "    Compute the 0/1/2 labels for frame `frame_idx` in folder `track_path`\n",
    "    using the same proximity + collision logic from your first script.\n",
    "    \"\"\"\n",
    "\n",
    "    # --- load point cloud & initial car pose (as before) ---\n",
    "    plyf   = os.path.join(track_path, f\"{frame_idx}.ply\")\n",
    "    car0f  = os.path.join(track_path, f\"{frame_idx}_car_state.json\")\n",
    "    coll0f = os.path.join(track_path, f\"{frame_idx}_collision_info.json\")\n",
    "    cloud = o3d.io.read_point_cloud(plyf)\n",
    "    pts   = np.asarray(cloud.points)                # shape (N,3)\n",
    "    car0  = json.load(open(car0f))\n",
    "    pos0, R0 = get_pose(car0)\n",
    "    world_pts = (R0 @ pts.T).T + pos0               # shape (N,3)\n",
    "\n",
    "    # --- build two Boolean masks across time (as before) ---\n",
    "    ever_close     = np.zeros(len(world_pts), dtype=bool)\n",
    "    ever_collision = np.zeros(len(world_pts), dtype=bool)\n",
    "    j = 1\n",
    "    while True:\n",
    "        carjf  = os.path.join(track_path, f\"{j}_car_state.json\")\n",
    "        colljf = os.path.join(track_path, f\"{j}_collision_info.json\")\n",
    "        if not (os.path.exists(carjf) and os.path.exists(colljf)):\n",
    "            break\n",
    "\n",
    "        carj  = json.load(open(carjf))\n",
    "        collj = json.load(open(colljf))\n",
    "        posj, _ = get_pose(carj)\n",
    "\n",
    "        # proximity mask\n",
    "        d_car = np.linalg.norm(world_pts - posj, axis=1)\n",
    "        ever_close |= (d_car < (threshold - 0.2))\n",
    "\n",
    "        # collision mask\n",
    "        if collj['has_collided']:\n",
    "            cp = collj['position']\n",
    "            pos_col = np.array([cp['x_val'], cp['y_val'], cp['z_val']], dtype=float)\n",
    "            d_col = np.linalg.norm(world_pts - pos_col, axis=1)\n",
    "            ever_collision |= (d_col < (threshold + 0.2))\n",
    "\n",
    "        j += 1\n",
    "\n",
    "    # --- continuous risk score in [0…1] ---\n",
    "    # simplest: risk = fraction of “close” points that also collide\n",
    "    # i.e. risk[i] = P(collided | point i was ever_close)\n",
    "    risk = np.zeros(len(world_pts), dtype=float)\n",
    "    # avoid divide-by-zero: only compute ratio where ever_close==True\n",
    "    mask = ever_close.copy()\n",
    "    # if a point was never “close” we can still give it a small base risk, e.g. 0\n",
    "    # for “close” points, define risk = 1 if ever_collision else 0\n",
    "    risk[mask] = ever_collision[mask].astype(float)\n",
    "    # — you can replace the above with a more nuanced continuous measure —\n",
    "    # e.g. risk = compute_cvar_cellwise(world_pts, …) normalized to [0,1]\n",
    "\n",
    "    # --- bin into num_bins discrete classes 0..num_bins-1 ---\n",
    "    # linspace edges from 0.0 up to 1.0\n",
    "    num_bins = 10\n",
    "    edges = np.linspace(0.0, 1.0, num_bins+1)\n",
    "    labels_10 = np.digitize(risk, edges[1:-1])  \n",
    "    # digitize returns 0..(num_bins-1) automatically\n",
    "\n",
    "    return labels_10\n",
    "\n",
    "# ——————— main processing loop ———————\n",
    "output_frame_dir = \"rendered_frames\"\n",
    "os.makedirs(output_frame_dir, exist_ok=True)\n",
    "\n",
    "data_root = \"../data\"\n",
    "threshold_check = 1.2   # or whatever you prefer\n",
    "k = 10                  # for KNN\n",
    "knn_thresh = 0.7        # for label propagation\n",
    "\n",
    "for file_num in tqdm(range(8), desc=\"Tracks\"):  # change upper bound as needed\n",
    "    track_folder = os.path.join(data_root, str(file_num))\n",
    "    names = os.listdir(track_folder)\n",
    "    ply_files = sorted(\n",
    "        [n for n in names if re.match(r\"^\\d+\\.ply$\", n)],\n",
    "        key=lambda x: int(x.split(\".\")[0])\n",
    "    )\n",
    "\n",
    "    for ply_name in tqdm(ply_files, desc=f\"Frames in track {file_num}\"):\n",
    "        idx = int(ply_name.split(\".\")[0])\n",
    "        # load point cloud\n",
    "        pcd = o3d.io.read_point_cloud(os.path.join(track_folder, ply_name))\n",
    "        xyz = np.asarray(pcd.points)\n",
    "\n",
    "        # --- compute labels on the fly instead of np.load(...) ---\n",
    "        labels = compute_labels_for_frame(track_folder, idx, threshold=threshold_check)\n",
    "        # labels are all zero\n",
    "        # labels = np.zeros(xyz.shape[0], dtype=np.int32) \n",
    "        # --- CSF ground/obstacle split ---\n",
    "        # csf = CSF.CSF()\n",
    "        # csf.params.bSloopSmooth = False\n",
    "        # csf.params.cloth_resolution = 0.03\n",
    "        # csf.params.rigidness = 1\n",
    "        # csf.params.iterations = 500\n",
    "        # csf.params.class_threshold = 0.1\n",
    "\n",
    "        # csf.setPointCloud(xyz)\n",
    "        # ground_idx = CSF.VecInt()\n",
    "        # non_ground_idx = CSF.VecInt()\n",
    "        # csf.do_filtering(ground_idx, non_ground_idx)\n",
    "\n",
    "        # ground_idx = np.array(list(ground_idx), dtype=int)\n",
    "        # obstacle_idx = np.array(list(non_ground_idx), dtype=int)\n",
    "\n",
    "        # csf_labels = np.zeros_like(labels, dtype=np.int32)\n",
    "        # csf_labels[ground_idx]  = 1\n",
    "        # csf_labels[obstacle_idx] = 2\n",
    "\n",
    "        # # --- KNN propagation to fill in any 0s ---\n",
    "        # labeled_idx   = np.where(csf_labels != 0)[0]\n",
    "        # unlabeled_idx = np.where(labels == 0)[0]\n",
    "\n",
    "        # if labeled_idx.size and unlabeled_idx.size:\n",
    "        #     knn = NearestNeighbors(n_neighbors=k).fit(xyz[labeled_idx])\n",
    "        #     _, nbrs = knn.kneighbors(xyz[unlabeled_idx])\n",
    "        #     for j, neigh in enumerate(nbrs):\n",
    "        #         most_common, cnt = Counter(csf_labels[labeled_idx[neigh]]).most_common(1)[0]\n",
    "        #         if cnt / k >= knn_thresh:\n",
    "        #             labels[unlabeled_idx[j]] = most_common\n",
    "\n",
    "        # out_npy = os.path.join(track_folder, f\"{idx}_labels_1.npy\")\n",
    "        # # print(out_npy)\n",
    "        # np.save(out_npy, labels)\n",
    "\n",
    "\n",
    "        t = labels.astype(np.float32) / (10 - 1)   # 0→0.0, 9→1.0\n",
    "\n",
    "        # build colors:  (R,G,B) = (t, 1–t, 0)\n",
    "        colors = np.stack([ t, 1.0 - t, np.zeros_like(t) ], axis=1)  # shape (N,3)\n",
    "\n",
    "        # attach to point cloud and visualize\n",
    "        pcd = o3d.geometry.PointCloud()\n",
    "        pcd.points = o3d.utility.Vector3dVector(xyz)\n",
    "        pcd.colors = o3d.utility.Vector3dVector(colors)\n",
    "\n",
    "        o3d.visualization.draw_geometries(\n",
    "            [pcd],\n",
    "            window_name=f\"Track {file_num} – Frame {idx}\",\n",
    "            width=800, height=600\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be91fd2c",
   "metadata": {},
   "source": [
    "### Visualize and captyure as IMage\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c96a679",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Frame in track 0: 100%|██████████| 31/31 [00:00<00:00, 33.45it/s]\n",
      "Frame in track 1: 100%|██████████| 146/146 [00:04<00:00, 34.48it/s]\n",
      "Frame in track 2: 100%|██████████| 1364/1364 [00:38<00:00, 35.84it/s]\n",
      "Frame in track 3: 100%|██████████| 437/437 [00:12<00:00, 35.98it/s]\n",
      "Frame in track 4: 100%|██████████| 292/292 [00:08<00:00, 35.81it/s]\n",
      "Frame in track 5: 100%|██████████| 45/45 [00:01<00:00, 36.32it/s]\n",
      "Frame in track 6: 100%|██████████| 1171/1171 [00:32<00:00, 36.52it/s]\n",
      "Frame in track 7: 100%|██████████| 1546/1546 [00:43<00:00, 35.46it/s]\n",
      "Tracks: 100%|██████████| 8/8 [02:20<00:00, 17.60s/it]\n"
     ]
    }
   ],
   "source": [
    "import open3d as o3d\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "from scipy.spatial.transform import Rotation as R\n",
    "\n",
    "\n",
    "output_frame_dir = \"rendered_frames\"\n",
    "os.makedirs(output_frame_dir, exist_ok=True)\n",
    "\n",
    "# --- build car mesh ---\n",
    "car_mesh = o3d.geometry.TriangleMesh.create_box(width=0.8, height=0.4, depth=0.3)\n",
    "car_mesh.compute_vertex_normals()\n",
    "car_mesh.paint_uniform_color([0.0, 0.0, 0.0])        # red car\n",
    "center = car_mesh.get_center()\n",
    "car_mesh.translate(-center)\n",
    "\n",
    "# --- build a front arrow ---\n",
    "arrow = o3d.geometry.TriangleMesh.create_arrow(\n",
    "    cylinder_radius=0.03,    # shaft thickness\n",
    "    cone_radius=0.06,        # tip thickness\n",
    "    cylinder_height=0.2,     # shaft length\n",
    "    cone_height=0.1          # tip length\n",
    ")\n",
    "arrow.compute_vertex_normals()\n",
    "arrow.paint_uniform_color([1.0, 0.0, 0.0])   # make it bright red\n",
    "\n",
    "# default arrow points along +Z, so rotate it to point along +X\n",
    "\n",
    "R_y_neg90 = R.from_euler('y', -np.pi/2).as_matrix()\n",
    "arrow.rotate(R_y_neg90, center=(0,0,0))\n",
    "arrow.translate([0.2, 0, 0.5])\n",
    "\n",
    "for file_num in tqdm(range(8), desc=\"Tracks\"):\n",
    "    file_output_dir = os.path.join(output_frame_dir, str(file_num))\n",
    "    os.makedirs(file_output_dir, exist_ok=True)\n",
    "\n",
    "    data_dir = f'../data/{file_num}'\n",
    "    ply_files = sorted([f for f in os.listdir(data_dir) if f.endswith('.ply')],\n",
    "                       key=lambda x: int(x[:-4]))\n",
    "\n",
    "    # one window per track\n",
    "    vis = o3d.visualization.Visualizer()\n",
    "    vis.create_window(width=1280, height=720, visible=False)\n",
    "\n",
    "    ctr = vis.get_view_control()\n",
    "    \n",
    "    for ply_name in tqdm(ply_files, desc=f\"Frame in track {file_num}\"):\n",
    "        idx = ply_name[:-4]\n",
    "\n",
    "        # --- load\n",
    "        pcd = o3d.io.read_point_cloud(os.path.join(data_dir, ply_name))\n",
    "        labels = np.load(os.path.join(data_dir, f\"{idx}_labels.npy\")).astype(int).reshape(-1)\n",
    "        with open(os.path.join(data_dir, f\"{idx}_car_state.json\")) as f:\n",
    "            car_state = json.load(f)\n",
    "\n",
    "        # --- colorize\n",
    "        cols = np.array([label_to_color.get(l, label_to_color[0]) for l in labels])\n",
    "        pcd.colors = o3d.utility.Vector3dVector(cols)\n",
    "        mirror_x = np.eye(4)\n",
    "        mirror_x[0, 0] = -1.0\n",
    "        pcd.transform(mirror_x)\n",
    "\n",
    "        # --- get pose & flatten to yaw only\n",
    "        pos, rot_full = get_pose(car_state)\n",
    "        pos[0] *= -1  # mirror X\n",
    "        rot_full = np.diag([-1, 1, 1]) @ rot_full  # mirror orientation\n",
    "\n",
    "        yaw = np.arctan2(rot_full[1, 0], rot_full[0, 0])\n",
    "        rot_flat = R.from_euler('z', yaw, degrees=False).as_matrix()\n",
    "\n",
    "        # --- chase‐cam in flattened frame\n",
    "        offset_local = np.array([-7, 0, -5.0])\n",
    "        lookat = car_mesh.get_center() + np.array([0.0, 0.0, 0.95])\n",
    "        cam_pos = car_mesh.get_center() + ( offset_local)\n",
    "\n",
    "        # --- render\n",
    "        vis.clear_geometries()\n",
    "        vis.add_geometry(pcd)\n",
    "        vis.add_geometry(car_mesh)  \n",
    "        vis.add_geometry(arrow)\n",
    "        ctr.set_lookat( lookat )\n",
    "        front = (lookat - cam_pos)\n",
    "        front /= np.linalg.norm(front)\n",
    "        ctr.set_front( front.tolist() )\n",
    "        ctr.set_up([0, 0, 1])\n",
    "        ctr.set_zoom(0.4)\n",
    "\n",
    "        vis.poll_events()\n",
    "        vis.update_renderer()\n",
    "        # vis.run()\n",
    "        # time.sleep(0.1)\n",
    "        img_path = os.path.join(file_output_dir, f\"{idx}.png\")\n",
    "        vis.capture_screen_image(img_path)\n",
    "\n",
    "    vis.destroy_window()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6241899d",
   "metadata": {},
   "source": [
    "Make video "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "25767a24",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Making videos:  12%|█▎        | 1/8 [00:00<00:04,  1.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " → Saved video: videos\\track_0.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Making videos:  25%|██▌       | 2/8 [00:03<00:11,  1.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " → Saved video: videos\\track_1.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Making videos:  38%|███▊      | 3/8 [00:29<01:05, 13.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " → Saved video: videos\\track_2.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Making videos:  50%|█████     | 4/8 [00:38<00:45, 11.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " → Saved video: videos\\track_3.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Making videos:  62%|██████▎   | 5/8 [00:43<00:27,  9.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " → Saved video: videos\\track_4.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Making videos:  75%|███████▌  | 6/8 [00:44<00:12,  6.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " → Saved video: videos\\track_5.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Making videos:  88%|████████▊ | 7/8 [01:07<00:11, 11.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " → Saved video: videos\\track_6.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Making videos: 100%|██████████| 8/8 [01:38<00:00, 12.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " → Saved video: videos\\track_7.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "\n",
    "# folders\n",
    "frame_folder       = 'rendered_frames'   # where your point images live, in subfolders 0,1,...,7\n",
    "camera_pic_folder  = '../data'           # where your camera images live, same subfolder structure\n",
    "output_folder      = 'videos'            # where the .mp4 files will be written\n",
    "\n",
    "# make sure output_folder exists\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# parameters\n",
    "fps = 30  # frames per second for the output video\n",
    "\n",
    "def resize_to_height(img, target_h):\n",
    "    h, w = img.shape[:2]\n",
    "    scale = target_h / float(h)\n",
    "    return cv2.resize(img, (int(w * scale), target_h))\n",
    "\n",
    "for track_id in tqdm(range(8), desc=\"Making videos\"):\n",
    "    cam_dir   = os.path.join(camera_pic_folder,  str(track_id))\n",
    "    point_dir = os.path.join(frame_folder,       str(track_id))\n",
    "    \n",
    "    # collect and sort PNGs by numeric name (e.g. \"0.png\", \"1.png\", ...)\n",
    "    files = sorted(\n",
    "        [f for f in os.listdir(cam_dir) if f.lower().endswith('.png')],\n",
    "        key=lambda fn: int(os.path.splitext(fn)[0])\n",
    "    )\n",
    "    if not files:\n",
    "        print(f\" → no images in {cam_dir}, skipping\")\n",
    "        continue\n",
    "\n",
    "    # load first pair to determine output size\n",
    "    p0 = cv2.imread(os.path.join(point_dir, files[0]))\n",
    "    c0 = cv2.imread(os.path.join(cam_dir,   files[0]))\n",
    "    if p0 is None or c0 is None:\n",
    "        raise RuntimeError(f\"Could not read {files[0]} from one of the folders\")\n",
    "\n",
    "    # match heights\n",
    "    H = max(p0.shape[0], c0.shape[0])\n",
    "    p0 = resize_to_height(p0, H)\n",
    "    c0 = resize_to_height(c0, H)\n",
    "\n",
    "    # setup video writer\n",
    "    W = p0.shape[1] + c0.shape[1]\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    out_path = os.path.join(output_folder, f'track_{track_id}.mp4')\n",
    "    writer = cv2.VideoWriter(out_path, fourcc, fps, (W, H))\n",
    "    \n",
    "    # write first frame\n",
    "    writer.write(cv2.hconcat([p0, c0]))\n",
    "\n",
    "    # process remaining frames\n",
    "    for fname in files[1:]:\n",
    "        p = cv2.imread(os.path.join(point_dir, fname))\n",
    "        c = cv2.imread(os.path.join(cam_dir,   fname))\n",
    "        if p is None or c is None:\n",
    "            print(f\"  ✗ skipping {fname} (failed to load)\")\n",
    "            continue\n",
    "        p = resize_to_height(p, H)\n",
    "        c = resize_to_height(c, H)\n",
    "        writer.write(cv2.hconcat([p, c]))\n",
    "\n",
    "    writer.release()\n",
    "    print(f\" → Saved video: {out_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "point",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
